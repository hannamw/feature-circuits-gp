{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/u/smarks/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from nnsight import LanguageModel\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from attribution import patching_effect\n",
    "from dictionary_learning import AutoEncoder, ActivationBuffer\n",
    "from dictionary_learning.interp import examine_dimension\n",
    "from dictionary_learning.utils import zst_to_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map=device)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ambiguous(split='train', seed=SEED):\n",
    "    t.manual_seed(seed)\n",
    "    data = pd.read_csv(f'data/{split}_data.csv')\n",
    "    labels = t.randint(0, 2, (len(data),)).to(device)\n",
    "    inputs = [\n",
    "        row['singular'].lower() if label == 0 else row['plural'].upper() for (_, row), label in zip(data.iterrows(), labels)\n",
    "    ]\n",
    "    return inputs, labels\n",
    "\n",
    "def data_unambiguous(split='train', seed=SEED):\n",
    "    t.manual_seed(seed)\n",
    "    data = pd.read_csv(f'data/{split}_data.csv')\n",
    "    feat1_labels = t.randint(0, 2, (len(data),)).to(device)\n",
    "    feat2_labels = t.randint(0, 2, (len(data),)).to(device)\n",
    "    inputs = []\n",
    "    for (_, row), label1, label2 in zip(data.iterrows(), feat1_labels, feat2_labels):\n",
    "        if label1 == 0 and label2 == 0:\n",
    "            inputs.append(row['singular'])\n",
    "        elif label1 == 0 and label2 == 1:\n",
    "            inputs.append(row['singular'].upper())\n",
    "        elif label1 == 1 and label2 == 0:\n",
    "            inputs.append(row['plural'])\n",
    "        elif label1 == 1 and label2 == 1:\n",
    "            inputs.append(row['plural'].upper())\n",
    "    return inputs, feat1_labels, feat2_labels\n",
    "\n",
    "def data_gen(ambiguous=True, split='train', seed=SEED):\n",
    "    if ambiguous:\n",
    "        return data_ambiguous(split=split, seed=seed)\n",
    "    else:\n",
    "        return data_unambiguous(split=split, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_ablations(\n",
    "        model,\n",
    "        inputs,\n",
    "        submodules,\n",
    "        dictionaries,\n",
    "        to_ablate,\n",
    "        out_fn,\n",
    "        inference=True,\n",
    "):\n",
    "    with model.invoke(inputs, fwd_args={'inference': inference}):\n",
    "        for submodule, dictionary in zip(submodules, dictionaries):\n",
    "            x = submodule.output\n",
    "            is_resid = (type(x.shape) == tuple)\n",
    "            if is_resid:\n",
    "                x = x[0]\n",
    "            x_hat = dictionary(x)\n",
    "            residual = x - x_hat\n",
    "\n",
    "            f = dictionary.encode(x)\n",
    "            ablation_idxs = t.Tensor(to_ablate[submodule]).long()\n",
    "            f[:, :, ablation_idxs] = 0.\n",
    "            x_hat = dictionary.decode(f)\n",
    "            if is_resid:\n",
    "                submodule.output[0][:] = x_hat # + residual\n",
    "            else:\n",
    "                submodule.output = x_hat # + residual\n",
    "            \n",
    "        out = out_fn(model).save()\n",
    "    return out.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(nn.Module):\n",
    "    def __init__(self, activation_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(activation_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x).squeeze(-1)\n",
    "        return logits.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 20\n",
    "layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control probe 1 accuracy: 0.9635036587715149\n",
      "Control probe 2 accuracy: 0.9781022071838379\n"
     ]
    }
   ],
   "source": [
    "inputs, feat1_labels, feat2_labels = data_gen(ambiguous=False, split='train')\n",
    "\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "probe1 = Probe(acts.shape[-1]).to(device)\n",
    "probe2 = Probe(acts.shape[-1]).to(device)\n",
    "opt1 = t.optim.AdamW(probe1.parameters(), lr=lr)\n",
    "opt2 = t.optim.AdamW(probe2.parameters(), lr=lr)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    opt1.zero_grad(), opt2.zero_grad()\n",
    "    logits1 = probe1(acts)\n",
    "    logits2 = probe2(acts)\n",
    "    loss1 = nn.BCELoss()(logits1, feat1_labels.float())\n",
    "    loss2 = nn.BCELoss()(logits2, feat2_labels.float())\n",
    "    loss1.backward(), loss2.backward()\n",
    "    opt1.step(), opt2.step()\n",
    "\n",
    "inputs, feat1_labels, feat2_labels = data_gen(ambiguous=False, split='test')\n",
    "\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "probs1 = probe1(acts)\n",
    "probs2 = probe2(acts)\n",
    "preds1, preds2 = probs1.round(), probs2.round()\n",
    "acc1 = (preds1 == feat1_labels).float().mean().item()\n",
    "acc2 = (preds2 == feat2_labels).float().mean().item()\n",
    "\n",
    "print(f'Control probe 1 accuracy: {acc1}')\n",
    "print(f'Control probe 2 accuracy: {acc2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on ambiguous data: 1.0\n",
      "feat1 accuracy: 0.5839415788650513\n",
      "feat2 accuracy: 0.9635036587715149\n"
     ]
    }
   ],
   "source": [
    "t.manual_seed(SEED)\n",
    "probe = Probe(512).to(device)\n",
    "optimizer = t.optim.AdamW(probe.parameters(), lr=lr)\n",
    "\n",
    "# train probe on ambiguous data\n",
    "inputs, labels = data_gen(ambiguous=True, split='train')\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "for _ in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    probs = probe(acts)\n",
    "    loss = nn.BCELoss()(probs, labels.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# get accuracy on ambiguous test set\n",
    "inputs, labels = data_gen(ambiguous=True, split='test')\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "preds = probe(acts).round()\n",
    "acc = (preds == labels).float().mean().item()\n",
    "print(f'Accuracy on ambiguous data: {acc}')\n",
    "\n",
    "# get accuracy on unambiguous test set\n",
    "inputs, feat1_labels, feat2_labels = data_gen(ambiguous=False, split='test')\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "preds = probe(acts).round()\n",
    "acc = (preds == feat1_labels).float().mean().item()\n",
    "print(f'feat1 accuracy: {acc}')\n",
    "preds = probe(acts).round()\n",
    "acc = (preds == feat2_labels).float().mean().item()\n",
    "print(f'feat2 accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "    Multindex: (450,), Value: 0.001137584331445396\n",
      "    Multindex: (1403,), Value: 0.008632320910692215\n",
      "    Multindex: (4726,), Value: 0.002920112805441022\n",
      "    Multindex: (8844,), Value: 0.0012917125131934881\n",
      "    Multindex: (9301,), Value: 0.0012395131634548306\n",
      "    Multindex: (10019,), Value: 0.001957895699888468\n",
      "    Multindex: (12580,), Value: 0.0022025764919817448\n",
      "    Multindex: (18519,), Value: 0.003057642839848995\n",
      "    Multindex: (20405,), Value: 0.0010994495823979378\n",
      "    Multindex: (23723,), Value: 0.002285792026668787\n",
      "    Multindex: (28583,), Value: 0.0012381786946207285\n",
      "    Multindex: (28762,), Value: 0.0012637594481930137\n",
      "    Multindex: (31378,), Value: 0.008632320910692215\n",
      "Layer 1:\n",
      "    Multindex: (12753,), Value: 0.006197110749781132\n",
      "    Multindex: (13537,), Value: 0.008146233856678009\n",
      "Layer 2:\n",
      "    Multindex: (2543,), Value: 0.0011143218725919724\n",
      "    Multindex: (12633,), Value: 0.003300841199234128\n",
      "    Multindex: (29926,), Value: 0.001003497396595776\n",
      "Layer 0:\n",
      "    Multindex: (1512,), Value: -0.007083915174007416\n",
      "    Multindex: (5125,), Value: -0.0010151092428714037\n",
      "    Multindex: (7655,), Value: -0.0023944389540702105\n",
      "    Multindex: (14663,), Value: -0.0021257929038256407\n",
      "    Multindex: (18956,), Value: -0.009658755734562874\n",
      "    Multindex: (20156,), Value: -0.0011104568839073181\n",
      "    Multindex: (21034,), Value: -0.01030351035296917\n",
      "    Multindex: (22920,), Value: -0.0015976147260516882\n",
      "    Multindex: (27094,), Value: -0.0017539591062813997\n",
      "    Multindex: (27183,), Value: -0.0011492000194266438\n",
      "    Multindex: (28489,), Value: -0.010939995758235455\n",
      "    Multindex: (29378,), Value: -0.00181278632953763\n",
      "    Multindex: (30694,), Value: -0.0012540434254333377\n",
      "    Multindex: (31206,), Value: -0.0021393971983343363\n",
      "Layer 1:\n",
      "    Multindex: (5048,), Value: -0.0016672968631610274\n",
      "    Multindex: (11997,), Value: -0.006828146055340767\n",
      "    Multindex: (14172,), Value: -0.016464419662952423\n",
      "    Multindex: (15924,), Value: -0.0010452655842527747\n",
      "    Multindex: (26929,), Value: -0.001194379641674459\n",
      "    Multindex: (27128,), Value: -0.0058854627422988415\n",
      "    Multindex: (29410,), Value: -0.0010280727874487638\n",
      "    Multindex: (31665,), Value: -0.0011301104677841067\n",
      "Layer 2:\n",
      "    Multindex: (1352,), Value: -0.012746963649988174\n",
      "    Multindex: (2183,), Value: -0.0030771372839808464\n",
      "    Multindex: (9222,), Value: -0.003090668236836791\n",
      "    Multindex: (11090,), Value: -0.0032364013604819775\n",
      "    Multindex: (27831,), Value: -0.0015852999640628695\n"
     ]
    }
   ],
   "source": [
    "submodules = [\n",
    "    model.gpt_neox.layers[i] for i in range(layer + 1)\n",
    "]\n",
    "dictionaries = []\n",
    "for i in range(layer + 1):\n",
    "    ae = AutoEncoder(512, 64 * 512).to(device)\n",
    "    ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/resid_out_layer{i}/5_32768/ae.pt'))\n",
    "    dictionaries.append(ae)\n",
    "\n",
    "def metric_fn(model):\n",
    "    return probe(model.gpt_neox.layers[layer].output[0][:,-1,:])\n",
    "\n",
    "inputs, labels = data_gen(ambiguous=True, split='train')\n",
    "\n",
    "neg_inputs, pos_inputs = [], []\n",
    "for x, label in zip(inputs, labels):\n",
    "    if label == 0:\n",
    "        neg_inputs.append(x)\n",
    "    else:\n",
    "        pos_inputs.append(x)\n",
    "\n",
    "\n",
    "neg_effects, _ = patching_effect(\n",
    "    neg_inputs,\n",
    "    None,\n",
    "    model,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    metric_fn,\n",
    "    method='ig'\n",
    ")\n",
    "\n",
    "neg_effects = {k : v.mean(dim=0).mean(dim=0) for k, v in neg_effects.items()}\n",
    "for i, submodule in enumerate(submodules):\n",
    "    print(f\"Layer {i}:\")\n",
    "    effect = neg_effects[submodule]\n",
    "    for feature_idx in t.nonzero(effect):\n",
    "        value = effect[tuple(feature_idx)]\n",
    "        if value > 0.001:\n",
    "            print(f\"    Multindex: {tuple(feature_idx.tolist())}, Value: {value}\")\n",
    "\n",
    "pos_effects, _ = patching_effect(\n",
    "    pos_inputs,\n",
    "    None,\n",
    "    model,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    metric_fn,\n",
    "    method='ig'\n",
    ")\n",
    "\n",
    "pos_effects = {k : v.mean(dim=0).mean(dim=0) for k, v in pos_effects.items()}\n",
    "\n",
    "for i, submodule in enumerate(submodules):\n",
    "    print(f\"Layer {i}:\")\n",
    "    effect = pos_effects[submodule]\n",
    "    for feature_idx in t.nonzero(effect):\n",
    "        value = effect[tuple(feature_idx)]\n",
    "        if -value > 0.001:\n",
    "            print(f\"    Multindex: {tuple(feature_idx.tolist())}, Value: {value}\")\n",
    "\n",
    "# total_effects = {\n",
    "#     k : -pos_effects[k] + neg_effects[k] for k in pos_effects.keys()\n",
    "# }\n",
    "# for i, submodule in enumerate(submodules):\n",
    "#     print(f\"Layer {i}:\")\n",
    "#     effect = total_effects[submodule]\n",
    "#     for feature_idx in t.nonzero(effect):\n",
    "#         value = effect[tuple(feature_idx)]\n",
    "#         if value > 0.001:\n",
    "#             print(f\"    Multindex: {tuple(feature_idx.tolist())}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/u/smarks/.local/lib/python3.8/site-packages/transformers/generation/utils.py:2388: UserWarning: Specified kernel cache directory is not writable! This disables kernel caching. Specified directory is /share/u/smarks/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1460.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MAN', 107.1137466430664), ('For', 97.23233032226562), ('From', 94.35887908935547), ('Sl', 91.1875228881836), ('Ret', 90.5478744506836), ('H', 86.20515441894531), ('ive', 84.82954406738281), ('New', 81.80145263671875), ('CI', 81.71781921386719), ('When', 80.9211654663086)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b2722373-1923\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b2722373-1923\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [[\"MAN\"], [\"For\"], [\"From\"], [\"Sl\"], [\"Ret\"], [\"H\"], [\"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"--\", \"recurs\", \"ive\"], [\"New\"], [\"CI\"], [\"When\"], [\"All\"], [\"j\"], [\"In\"], [\"In\"], [\"c\"], [\"Ad\"], [\"At\"], [\"Al\"], [\"During\"], [\"M\"], [\"M\"], [\"Aut\"], [\"D\"], [\"D\"], [\"Ti\"], [\"Ex\"], [\"Vol\"], [\"Major\"], [\"But\"], [\"This\"]], \"activations\": [[[[107.1137466430664]]], [[[97.23233032226562]]], [[[94.35887908935547]]], [[[91.1875228881836]]], [[[90.5478744506836]]], [[[86.20515441894531]]], [[[66.41400146484375]], [[66.41397857666016]], [[66.41401672363281]], [[66.41400146484375]], [[66.41403198242188]], [[66.41402435302734]], [[66.41401672363281]], [[66.41400146484375]], [[66.41402435302734]], [[66.4140396118164]], [[66.41401672363281]], [[66.41400909423828]], [[66.41397857666016]], [[66.41398620605469]], [[66.41403198242188]], [[66.41403198242188]], [[66.4140396118164]], [[66.41402435302734]], [[66.41400146484375]], [[66.41403198242188]], [[66.41401672363281]], [[66.41402435302734]], [[66.41400909423828]], [[66.41402435302734]], [[66.4140396118164]], [[66.41401672363281]], [[66.41401672363281]], [[66.4140396118164]], [[66.41403198242188]], [[66.41400909423828]], [[66.4140396118164]], [[66.41404724121094]], [[66.41403198242188]], [[66.41401672363281]], [[66.41401672363281]], [[66.41402435302734]], [[66.41402435302734]], [[66.41403198242188]], [[66.41403198242188]], [[66.41401672363281]], [[66.41401672363281]], [[66.41400146484375]], [[66.41400909423828]], [[66.41399383544922]], [[66.4140396118164]], [[66.41404724121094]], [[66.41398620605469]], [[66.41402435302734]], [[66.41400909423828]], [[66.41403198242188]], [[66.41403198242188]], [[66.41402435302734]], [[66.41402435302734]], [[66.41402435302734]], [[66.41402435302734]], [[66.41403198242188]], [[66.41398620605469]], [[66.41400909423828]], [[66.41401672363281]], [[66.41400909423828]], [[66.4140396118164]], [[66.4140396118164]], [[66.41399383544922]], [[66.41400146484375]], [[66.41401672363281]], [[66.41401672363281]], [[66.41402435302734]], [[66.41400146484375]], [[66.41403198242188]], [[66.41401672363281]], [[66.41403198242188]], [[66.41398620605469]], [[66.41400909423828]], [[66.41402435302734]], [[66.41401672363281]], [[66.41403198242188]], [[66.41402435302734]], [[66.41403198242188]], [[66.41404724121094]], [[66.41401672363281]], [[66.41400146484375]], [[66.41403198242188]], [[66.41402435302734]], [[66.41401672363281]], [[66.41404724121094]], [[66.41403198242188]], [[66.41400909423828]], [[66.41402435302734]], [[66.41405487060547]], [[66.4140396118164]], [[66.41400909423828]], [[66.41402435302734]], [[66.41400146484375]], [[66.41403198242188]], [[66.41400909423828]], [[66.41402435302734]], [[66.41404724121094]], [[66.41401672363281]], [[66.41400909423828]], [[66.41402435302734]], [[66.41402435302734]], [[66.41403198242188]], [[66.41400909423828]], [[66.41402435302734]], [[66.41402435302734]], [[66.4140396118164]], [[66.41400146484375]], [[66.41403198242188]], [[66.41400909423828]], [[66.41401672363281]], [[66.41400909423828]], [[66.41407012939453]], [[66.41400146484375]], [[66.41400909423828]], [[66.4140396118164]], [[66.4140396118164]], [[66.41403198242188]], [[48.88430404663086]], [[42.3123779296875]], [[84.82954406738281]]], [[[81.80145263671875]]], [[[81.71781921386719]]], [[[80.9211654663086]]], [[[80.3303451538086]]], [[[79.77943420410156]]], [[[79.73715209960938]]], [[[79.73715209960938]]], [[[79.6659927368164]]], [[[79.49032592773438]]], [[[79.1098403930664]]], [[[79.1085433959961]]], [[[77.99986267089844]]], [[[76.42451477050781]]], [[[76.42451477050781]]], [[[76.24850463867188]]], [[[75.58638763427734]]], [[[75.58638763427734]]], [[[75.5649642944336]]], [[[74.51052856445312]]], [[[74.44656372070312]]], [[[74.23029327392578]]], [[[74.22212219238281]]], [[[73.78429412841797]]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f1194084670>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_idx = 2\n",
    "feat_idx = 12633\n",
    "\n",
    "submodule = submodules[component_idx]\n",
    "dictionary = dictionaries[component_idx]\n",
    "\n",
    "# interpret some features\n",
    "data = zst_to_generator('/share/data/datasets/pile/the-eye.eu/public/AI/pile/train/00.jsonl.zst')\n",
    "buffer = ActivationBuffer(\n",
    "    data,\n",
    "    model,\n",
    "    [submodule],\n",
    "    out_feats=512,\n",
    "    in_batch_size=128,\n",
    "    n_ctxs=512,\n",
    ")\n",
    "\n",
    "out = examine_dimension(\n",
    "    model,\n",
    "    submodule,\n",
    "    buffer,\n",
    "    dictionary,\n",
    "    dim_idx=feat_idx,\n",
    ")\n",
    "print(out['top_tokens'])\n",
    "out['top_contexts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 0.7661039233207703, after: 0.6993085741996765\n"
     ]
    }
   ],
   "source": [
    "input = \"YARNS\"\n",
    "\n",
    "to_ablate = {\n",
    "    submodules[0] : [\n",
    "        # 1512, # all caps tokens ending in S\n",
    "        # 5125, # all caps text + other random stuff\n",
    "        # 7655, # all caps tokens, with a preference towards ending in S\n",
    "        14663, # certain all caps tokens\n",
    "        # 18956, # certain tokens ending with s\n",
    "        20156, # single all caps letters\n",
    "        # 21034, # the token S\n",
    "        22920, # the token B\n",
    "        27094, # certain all caps tokens\n",
    "        # 27183, # certain all caps tokens + other random stuff (including ')\n",
    "        28489, # all caps text\n",
    "        # 29378, # plural words\n",
    "        30694, # certain all caps text\n",
    "        31206, # certain all caps text\n",
    "    ],\n",
    "    submodules[1] : [\n",
    "        # 5048, # the token S\n",
    "        11997, # certain all caps text\n",
    "        14172, # all caps text\n",
    "        # 15924, # tokens ending with es\n",
    "        26929, # certain all caps text\n",
    "        # 27128, # all caps tokens ending with S\n",
    "        # 29410, # all caps text + other random stuff\n",
    "        31665, # certain all caps text\n",
    "    ],\n",
    "    submodules[2] : [\n",
    "        1352, # certain all caps text\n",
    "        # 2183, # plural words starting with a capital letter\n",
    "        # 9222, # tokens ending with es\n",
    "        11090, # certain all caps text\n",
    "        # 27831, # the token S\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "with model.invoke(input):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "pred_before = probe(acts).item()\n",
    "\n",
    "with model.invoke(input):\n",
    "    for submodule, dictionary in zip(submodules, dictionaries):\n",
    "        x = submodule.output\n",
    "        is_resid = type(x.shape) == tuple\n",
    "        if is_resid:\n",
    "            x = x[0]\n",
    "        x_hat = dictionary(x)\n",
    "        residual = x - x_hat\n",
    "        \n",
    "        f = dictionary.encode(x)\n",
    "        ablation_idxs = to_ablate[submodule]\n",
    "        for idx in ablation_idxs:\n",
    "            f[..., idx] = 0\n",
    "        x_hat = dictionary.decode(f)\n",
    "        if is_resid:\n",
    "            submodule.output[0][:] = x_hat + residual\n",
    "        else:\n",
    "            submodule.output = x_hat + residual\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "pred_after = probe(acts).item()\n",
    "\n",
    "print(f'before: {pred_before}, after: {pred_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on ambiguous data: 0.7591241002082825\n",
      "feat1 accuracy: 0.5620437860488892\n",
      "feat2 accuracy: 0.7226277589797974\n"
     ]
    }
   ],
   "source": [
    "def get_acts(model):\n",
    "    return model.gpt_neox.layers[layer].output[0][:,-1,:]\n",
    "\n",
    "# get accuracy on ambiguous test set\n",
    "inputs, labels = data_gen(ambiguous=True, split='test')\n",
    "acts = run_with_ablations(\n",
    "    model,\n",
    "    inputs,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    to_ablate,\n",
    "    get_acts,\n",
    ")\n",
    "preds = probe(acts.clone()).round()\n",
    "acc = (preds == labels).float().mean().item()\n",
    "print(f'Accuracy on ambiguous data: {acc}')\n",
    "\n",
    "# get accuracy on unambiguous test set\n",
    "inputs, feat1_labels, feat2_labels = data_gen(ambiguous=False, split='test')\n",
    "acts = run_with_ablations(\n",
    "    model,\n",
    "    inputs,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    to_ablate,\n",
    "    get_acts,\n",
    ")\n",
    "preds = probe(acts.clone()).round()\n",
    "acc = (preds == feat1_labels).float().mean().item()\n",
    "print(f'feat1 accuracy: {acc}')\n",
    "preds = probe(acts.clone()).round()\n",
    "acc = (preds == feat2_labels).float().mean().item()\n",
    "print(f'feat2 accuracy: {acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat1 accuracy: 0.8029196858406067\n",
      "feat2 accuracy: 0.8832116723060608\n"
     ]
    }
   ],
   "source": [
    "# train probes on unambiguous data\n",
    "inputs, feat1_labels, feat2_labels = data_gen(ambiguous=False, split='train')\n",
    "\n",
    "acts = run_with_ablations(\n",
    "    model,\n",
    "    inputs,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    to_ablate,\n",
    "    get_acts,\n",
    ")\n",
    "acts = acts.clone()\n",
    "\n",
    "t.manual_seed(SEED)\n",
    "probe1 = Probe(acts.shape[-1]).to(device)\n",
    "probe2 = Probe(acts.shape[-1]).to(device)\n",
    "opt1 = t.optim.AdamW(probe1.parameters(), lr=lr)\n",
    "opt2 = t.optim.AdamW(probe2.parameters(), lr=lr)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    opt1.zero_grad(), opt2.zero_grad()\n",
    "    logits1 = probe1(acts)\n",
    "    logits2 = probe2(acts)\n",
    "    loss1 = nn.BCELoss()(logits1, feat1_labels.float())\n",
    "    loss2 = nn.BCELoss()(logits2, feat2_labels.float())\n",
    "    loss1.backward(), loss2.backward()\n",
    "    opt1.step(), opt2.step()\n",
    "\n",
    "# get accuracy on unambiguous test set\n",
    "inputs, feat1_labels, feat2_labels = data_gen(ambiguous=False, split='test')\n",
    "acts = run_with_ablations(\n",
    "    model,\n",
    "    inputs,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    to_ablate,\n",
    "    get_acts,\n",
    ")\n",
    "acts = acts.clone()\n",
    "\n",
    "probs1 = probe1(acts)\n",
    "probs2 = probe2(acts)\n",
    "preds1, preds2 = probs1.round(), probs2.round()\n",
    "acc1 = (preds1 == feat1_labels).float().mean().item()\n",
    "acc2 = (preds2 == feat2_labels).float().mean().item()\n",
    "\n",
    "print(f'feat1 accuracy: {acc1}')\n",
    "print(f'feat2 accuracy: {acc2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on ambiguous data: 0.941605806350708\n",
      "feat1 accuracy: 0.6204379796981812\n",
      "feat2 accuracy: 0.8394160270690918\n"
     ]
    }
   ],
   "source": [
    "# retrain probe on ablated model\n",
    "t.manual_seed(SEED)\n",
    "probe_new = Probe(512).to(device)\n",
    "optimizer = t.optim.AdamW(probe_new.parameters(), lr=lr)\n",
    "\n",
    "# train probe on ambiguous data\n",
    "inputs, labels = data_gen(ambiguous=True, split='train')\n",
    "acts = run_with_ablations(\n",
    "    model,\n",
    "    inputs,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    to_ablate,\n",
    "    get_acts,\n",
    ")\n",
    "acts = acts.clone()\n",
    "\n",
    "for _ in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    probs = probe_new(acts)\n",
    "    loss = nn.BCELoss()(probs, labels.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# get accuracy on ambiguous test set\n",
    "inputs, labels = data_gen(ambiguous=True, split='test')\n",
    "acts = run_with_ablations(\n",
    "    model,\n",
    "    inputs,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    to_ablate,\n",
    "    get_acts,\n",
    ")\n",
    "acts = acts.clone()\n",
    "preds = probe_new(acts).round()\n",
    "acc = (preds == labels).float().mean().item()\n",
    "print(f'Accuracy on ambiguous data: {acc}')\n",
    "\n",
    "# get accuracy on unambiguous test set\n",
    "inputs, feat1_labels, feat2_labels = data_gen(ambiguous=False, split='test')\n",
    "acts = run_with_ablations(\n",
    "    model,\n",
    "    inputs,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    to_ablate,\n",
    "    get_acts,\n",
    ")\n",
    "acts = acts.clone()\n",
    "preds = probe_new(acts).round()\n",
    "acc = (preds == feat1_labels).float().mean().item()\n",
    "print(f'feat1 accuracy: {acc}')\n",
    "preds = probe_new(acts).round()\n",
    "acc = (preds == feat2_labels).float().mean().item()\n",
    "print(f'feat2 accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat1 accuracy: 0.6204379796981812\n",
      "feat2 accuracy: 0.8686131238937378\n"
     ]
    }
   ],
   "source": [
    "# classify things based on the difference between the probe and probe_new predictions\n",
    "inputs, feat1_labels, feat2_labels = data_gen(ambiguous=False, split='test')\n",
    "\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "acts_new = run_with_ablations(\n",
    "    model,\n",
    "    inputs,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    to_ablate,\n",
    "    get_acts,\n",
    ")\n",
    "acts_new = acts_new.clone()\n",
    "\n",
    "probs1 = probe(acts)\n",
    "probs2 = probe_new(acts_new)\n",
    "diffs = probs2 - probs1\n",
    "preds = (probs1 + diffs * 0.8).round()\n",
    "# preds = t.where(\n",
    "#     diffs.abs() > .1,\n",
    "#     (diffs > 0).float(),\n",
    "#     probs2.round()\n",
    "# )\n",
    "\n",
    "acc = (preds == feat1_labels).float().mean().item()\n",
    "print(f'feat1 accuracy: {acc}')\n",
    "acc = (preds == feat2_labels).float().mean().item()\n",
    "print(f'feat2 accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beef 0.0 0.04246163368225098 0.04246163368225098\n",
      "tomatoes 0.0 0.01407528854906559 0.014232482761144638\n",
      "headphone 0.0 0.0004125593404751271 0.0004125595442019403\n",
      "ELECTRON 0.0 0.9458839893341064 0.662473201751709\n",
      "seatbelt 0.0 0.002296003745868802 0.002296003745868802\n",
      "GOBLINS 1.0 0.9927135109901428 0.9583725333213806\n",
      "TRAVELER 0.0 0.9688680768013 0.8200774192810059\n",
      "DANCE 0.0 0.35750260949134827 0.13039857149124146\n",
      "parrot 0.0 0.0020670697558671236 0.002067072782665491\n",
      "minerals 0.0 0.06108663231134415 0.06108663231134415\n",
      "refugee 0.0 0.09666279703378677 0.09418341517448425\n",
      "cabinet 0.0 0.015743708238005638 0.015743713825941086\n",
      "RUG 0.0 0.6748154759407043 0.4474864602088928\n",
      "doctor 0.0 0.00024147509247995913 0.00024147488875314593\n",
      "cookies 0.0 0.037880077958106995 0.034380584955215454\n",
      "bicycle 0.0 0.019201841205358505 0.0192018523812294\n",
      "toothbrushes 0.0 0.21269121766090393 0.211523175239563\n",
      "zoos 0.0 0.05740008503198624 0.05740008503198624\n",
      "ROADS 1.0 0.539910614490509 0.5258908867835999\n",
      "butter 0.0 0.008368565700948238 0.008368561044335365\n",
      "POEMS 1.0 0.9880875945091248 0.9800741076469421\n",
      "stream 0.0 0.00015327142318710685 0.00015327127766795456\n",
      "RHINOCEROSES 1.0 0.9991440773010254 0.9958452582359314\n",
      "soldiers 0.0 0.059281572699546814 0.05875200033187866\n",
      "festivals 0.0 0.1231389120221138 0.12313881516456604\n",
      "PIANOS 0.0 0.9580724239349365 0.7296121716499329\n",
      "NAILS 1.0 0.9942517280578613 0.9722169637680054\n",
      "CHAPTERS 1.0 0.9974505305290222 0.9920431971549988\n",
      "trees 0.0 0.000711871194653213 0.000550665135961026\n",
      "TOASTERS 0.0 0.9562177062034607 0.6871966123580933\n",
      "hawk 0.0 0.027996132150292397 0.026077423244714737\n",
      "plate 0.0 0.00015180400805547833 0.00015180400805547833\n",
      "THERMOMETERS 1.0 0.9987780451774597 0.9843416810035706\n",
      "DAISIES 1.0 0.9886110424995422 0.9516909122467041\n",
      "ducks 1.0 0.9161551594734192 0.9139452576637268\n",
      "zebu 0.0 0.05128225311636925 0.05110885202884674\n",
      "PORKS 1.0 0.9178125262260437 0.90382319688797\n",
      "HYDRANGEA 1.0 0.9835972189903259 0.9492297172546387\n",
      "RACKET 0.0 0.693408191204071 0.24840864539146423\n",
      "scarf 0.0 0.16297408938407898 0.13800691068172455\n",
      "magazine 0.0 0.01252501830458641 0.012108368799090385\n",
      "xylophone 0.0 0.05087375268340111 0.05002483353018761\n",
      "outlets 0.0 0.0026805317029356956 0.0026780152693390846\n",
      "mixers 0.0 0.2907540798187256 0.2907547950744629\n",
      "facts 0.0 0.0004152132314629853 0.0004152132314629853\n",
      "COMPUTERS 1.0 0.9983575940132141 0.9923804998397827\n",
      "houses 0.0 0.0006488774088211358 0.0006488776416517794\n",
      "cover 0.0 0.0011467809090390801 0.0011467798613011837\n",
      "treats 1.0 0.601621150970459 0.5766749382019043\n",
      "VIOLINS 1.0 0.967982828617096 0.9883757829666138\n",
      "achievement 0.0 0.004612194374203682 0.004612196236848831\n",
      "chords 0.0 0.07726689428091049 0.07726684212684631\n",
      "SQUARE 0.0 0.9374995231628418 0.6248924732208252\n",
      "pens 0.0 0.1501818597316742 0.1503911018371582\n",
      "immigrant 0.0 0.10891028493642807 0.10725165158510208\n",
      "princes 0.0 0.01728411577641964 0.016732232645154\n",
      "forests 1.0 0.763244092464447 0.763137698173523\n",
      "jamboree 0.0 0.10090913623571396 0.09771107137203217\n",
      "HOSE 1.0 0.9657225608825684 0.9591091871261597\n",
      "TALENT 0.0 0.903074324131012 0.6218684315681458\n",
      "LIZARD 1.0 0.6439082026481628 0.664997935295105\n",
      "universe 0.0 0.0871344804763794 0.08001405000686646\n",
      "meal 0.0 0.005332706030458212 0.0053327083587646484\n",
      "relaxation 0.0 0.3822648525238037 0.3808983564376831\n",
      "LAKE 1.0 0.9980334639549255 0.9968551397323608\n",
      "breads 0.0 0.156701922416687 0.12140227854251862\n",
      "leaders 0.0 0.1653897613286972 0.16605277359485626\n",
      "COASTER 0.0 0.8607373237609863 0.5591104626655579\n",
      "walnuts 0.0 0.005125007126480341 0.005090867169201374\n",
      "REMOTES 1.0 0.9925969839096069 0.9724225401878357\n",
      "QUETZALS 1.0 0.9905427098274231 0.9480177164077759\n",
      "ROCKS 0.0 0.983881950378418 0.9136683940887451\n",
      "cake 0.0 0.0006054620025679469 0.0006054617115296423\n",
      "sugars 0.0 0.05869286507368088 0.055769722908735275\n",
      "rabbit 0.0 0.0012889666249975562 0.0012889666249975562\n",
      "meters 0.0 0.012139041908085346 0.012139036320149899\n",
      "elks 0.0 0.18253420293331146 0.18253353238105774\n",
      "tables 0.0 0.0008255351567640901 0.0005155396065674722\n",
      "panda 0.0 0.0051186541095376015 0.005125423427671194\n",
      "PIZZAS 0.0 0.930083155632019 0.6590759754180908\n",
      "oven 0.0 0.002303321845829487 0.002303325105458498\n",
      "ALMONDS 1.0 0.988341748714447 0.9546549916267395\n",
      "ring 0.0 5.2716735808644444e-05 5.2716783102368936e-05\n",
      "tunes 0.0 0.05021281912922859 0.047787707298994064\n",
      "tourist 0.0 0.011485638096928596 0.011505821719765663\n",
      "DISCUSSION 0.0 0.6336621642112732 0.34857800602912903\n",
      "STUDENTS 0.0 0.9262995719909668 0.709352970123291\n",
      "REFEREE 0.0 0.990777850151062 0.6195545792579651\n",
      "SNACKS 0.0 0.9623735547065735 0.8261628150939941\n",
      "knives 0.0 0.08726716786623001 0.08397229015827179\n",
      "DAFFODILS 1.0 0.9918740391731262 0.9917200803756714\n",
      "waterfalls 0.0 0.023064447566866875 0.020762663334608078\n",
      "spheres 0.0 0.009894157759845257 0.009894154034554958\n",
      "ISSUES 1.0 0.9995026588439941 0.9930980801582336\n",
      "BLACKBERRIES 1.0 0.8971524834632874 0.8850902915000916\n",
      "DINOSAURS 1.0 0.9911332726478577 0.9710839986801147\n",
      "GRASSES 1.0 0.998316764831543 0.9886425137519836\n",
      "YARNS 0.0 0.7661040425300598 0.699308454990387\n",
      "UTENSILS 1.0 0.9926578402519226 0.9809978604316711\n",
      "FABLE 0.0 0.5461746454238892 0.1872704178094864\n",
      "STRATEGY 0.0 0.898637056350708 0.5512041449546814\n",
      "helmets 0.0 0.01614484190940857 0.01350180059671402\n",
      "TASKS 0.0 0.9732210636138916 0.8346632719039917\n",
      "STRAWBERRIES 1.0 0.9944102168083191 0.9710320234298706\n",
      "walruses 0.0 0.03083471767604351 0.030686862766742706\n",
      "FLAMINGOS 0.0 0.9813030362129211 0.6736391186714172\n",
      "junipers 0.0 0.3052775263786316 0.30932125449180603\n",
      "jackals 0.0 0.1428365409374237 0.14283667504787445\n",
      "PANS 0.0 0.974245011806488 0.8932762145996094\n",
      "picture 0.0 0.00023718008014839143 0.00023718008014839143\n",
      "bears 0.0 0.016821783035993576 0.01682179979979992\n",
      "mirror 0.0 0.005386590491980314 0.0037250302266329527\n",
      "zephyrs 0.0 0.30951857566833496 0.2626323103904724\n",
      "ISLANDS 1.0 0.9965392351150513 0.9835261702537537\n",
      "donkey 0.0 0.0013477120082825422 0.00142389303073287\n",
      "BULBS 0.0 0.9703730344772339 0.6809117197990417\n",
      "desk 0.0 0.06836309283971786 0.06386297196149826\n",
      "nickels 0.0 0.02281871624290943 0.02281876467168331\n",
      "apples 0.0 0.05062790960073471 0.05062802508473396\n",
      "bird 0.0 0.0008373097516596317 0.0008373097516596317\n",
      "TRUCKS 0.0 0.9919413328170776 0.8936992883682251\n",
      "POOL 1.0 0.605867862701416 0.647011935710907\n",
      "dolphins 0.0 0.09179390221834183 0.09179391711950302\n",
      "yeti 0.0 0.007653664331883192 0.007653671316802502\n",
      "TURTLE 0.0 0.75026535987854 0.30921950936317444\n",
      "lemons 0.0 0.050334129482507706 0.04972037672996521\n",
      "burgers 0.0 0.32927027344703674 0.3015080988407135\n",
      "miner 0.0 0.14681680500507355 0.14681655168533325\n",
      "VOICES 1.0 0.9923836588859558 0.9924094676971436\n",
      "SEASONS 1.0 0.9965851306915283 0.9905515909194946\n",
      "PROTONS 1.0 0.9329134821891785 0.9702352285385132\n",
      "pencil 0.0 0.004734545946121216 0.004731989931315184\n",
      "fruit 0.0 0.0025156717747449875 0.0025156729388982058\n",
      "NEWS 1.0 0.9186640381813049 0.9930968880653381\n",
      "BATTERY 0.0 0.8748708963394165 0.4784638285636902\n",
      "JAR 0.0 0.8483402132987976 0.6855067014694214\n",
      "LINE 0.0 0.2823949158191681 0.2420176863670349\n"
     ]
    }
   ],
   "source": [
    "for x, prob1, prob2, pred in zip(inputs, probs1, probs2, preds):\n",
    "    print(x, pred.item(), prob1.item(), prob2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.6879e-02,  2.0250e-02, -1.3686e-04,  2.3178e-01,  1.6529e-03,\n",
       "         6.6891e-02,  2.7669e-01,  1.0507e-01, -2.0387e-04,  9.0288e-02,\n",
       "         1.3871e-01,  2.7971e-02,  2.8520e-01, -1.7768e-04,  2.1047e-01,\n",
       "         5.7020e-02,  4.4652e-01, -2.1454e-02,  5.7701e-01,  2.8447e-02,\n",
       "         8.5847e-02,  2.5172e-05,  1.0240e-02,  3.1668e-01,  1.2039e-01,\n",
       "         3.1745e-01,  1.5877e-01,  2.4371e-03, -5.2675e-04,  1.5538e-01,\n",
       "         1.2155e-01, -9.7485e-05,  2.5782e-02,  5.9511e-02,  7.9205e-02,\n",
       "         2.8743e-02,  9.1319e-02,  5.9899e-02,  4.1422e-01,  2.7963e-01,\n",
       "         3.3364e-02,  7.9152e-02,  7.3441e-03,  4.3555e-01, -3.0199e-04,\n",
       "         6.6104e-03, -3.7750e-04, -4.0154e-04,  3.5560e-01,  5.5813e-02,\n",
       "         2.9123e-04,  4.7253e-01,  2.7764e-01,  3.6436e-01, -3.0451e-02,\n",
       "         7.5291e-02,  2.3076e-01,  1.6617e-01,  1.3763e-01,  3.0491e-01,\n",
       "         3.5337e-01,  1.4857e-01, -3.3222e-04,  3.4590e-01,  2.2563e-02,\n",
       "         4.7432e-01,  4.9966e-01,  3.7437e-01,  1.4534e-02,  8.9933e-02,\n",
       "         4.6826e-02,  1.0760e-01, -2.1836e-04,  4.0180e-01, -4.5381e-04,\n",
       "         7.4128e-02,  2.3738e-01, -1.6298e-04,  2.8073e-02,  3.9166e-01,\n",
       "        -1.8924e-03,  1.6548e-01, -2.8274e-05,  2.4951e-01,  3.3708e-02,\n",
       "        -1.6052e-01,  3.1788e-01,  2.6570e-01,  2.4708e-01,  2.0883e-01,\n",
       "         3.2472e-02,  5.9323e-02,  5.8550e-03,  1.1058e-02,  2.1870e-01,\n",
       "         5.9374e-02,  5.4030e-02,  4.4912e-01,  4.0839e-02,  2.2150e-01,\n",
       "         2.8928e-01,  6.1337e-03,  1.3383e-01,  6.0789e-02,  4.7117e-01,\n",
       "         1.8734e-01,  2.9516e-01,  4.3300e-01,  5.6949e-02, -7.9217e-05,\n",
       "         1.5351e-01, -1.7118e-03,  3.2255e-01,  1.3989e-02, -3.3647e-04,\n",
       "         3.1665e-01,  1.7249e-01, -3.8858e-03,  1.8510e-01, -5.6725e-04,\n",
       "         9.6146e-02,  4.8084e-01,  4.4225e-01,  5.2506e-02,  3.0166e-01,\n",
       "         5.9592e-03,  2.6451e-01,  7.8514e-02,  1.8359e-02,  4.1893e-02,\n",
       "         8.6697e-02,  1.6510e-02, -1.5133e-03,  8.2302e-02,  4.3029e-01,\n",
       "         1.9416e-01, -1.0982e-01], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs2 - probs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ling acc: 0.9539930555555556\n",
      "surface acc: 0.6663995726495726\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json('/share/data/datasets/msgs/syntactic_category_lexical_content_the/test.jsonl', lines=True)\n",
    "\n",
    "ling_accs, surface_accs = [], []\n",
    "# get accuracy on test data\n",
    "for batch_idx in range(len(test_data) // batch_size):\n",
    "    inputs = test_data['sentence'][batch_idx * batch_size:(batch_idx + 1) * batch_size].tolist()\n",
    "    ling_labels = test_data['linguistic_feature_label'][batch_idx * batch_size:(batch_idx + 1) * batch_size].tolist()\n",
    "    surface_labels = test_data['surface_feature_label'][batch_idx * batch_size:(batch_idx + 1) * batch_size].tolist()\n",
    "\n",
    "    with model.invoke(inputs) as invoker:\n",
    "        hidden_states = model.gpt_neox.layers[-3].output[0].save()\n",
    "    \n",
    "    with t.no_grad():\n",
    "        preds = probe(hidden_states.value)\n",
    "        ling_acc = (preds.round() == t.Tensor(ling_labels).to('cuda:0')).float().mean()\n",
    "        surface_acc = (preds.round() == t.Tensor(surface_labels).to('cuda:0')).float().mean()\n",
    "        ling_accs.append(ling_acc.item())\n",
    "        surface_accs.append(surface_acc.item())\n",
    "\n",
    "print('ling acc:', sum(ling_accs) / len(ling_accs))\n",
    "print('surface acc:', sum(surface_accs) / len(surface_accs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attribution import patching_effect\n",
    "from dictionary_learning.dictionary import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4021, 0.0954], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = \"All grandsons do resemble the print and Debra is an organized child.\"\n",
    "patch = \"All grandsons do resemble a print and Debra is an banana child.\"\n",
    "\n",
    "with model.invoke([clean, patch]) as invoker:\n",
    "    hidden_states = model.gpt_neox.layers[-3].output[0].save()\n",
    "\n",
    "with t.no_grad():\n",
    "    preds = probe(hidden_states.value)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn(model):\n",
    "    return probe(model.gpt_neox.layers[-3].output[0])\n",
    "\n",
    "submodules = [\n",
    "    model.gpt_neox.layers[i] for i in range(4)\n",
    "] + [\n",
    "    model.gpt_neox.layers[i].mlp for i in range(4)\n",
    "]\n",
    "dictionaries = []\n",
    "for i in range(4):\n",
    "    dictionary = AutoEncoder(512, 64 * 512).to(device)\n",
    "    dictionary.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/resid_out_layer{i}/0_32768/ae.pt'))\n",
    "    dictionaries.append(dictionary)\n",
    "for i in range(4):\n",
    "    dictionary = AutoEncoder(512, 64 * 512).to(device)\n",
    "    dictionary.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/mlp_out_layer{i}/1_32768/ae.pt'))\n",
    "    dictionaries.append(dictionary)\n",
    "\n",
    "out = patching_effect(\n",
    "    clean,\n",
    "    patch,\n",
    "    model,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    metric_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total effect: tensor([-0.7627], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Layer 0:\n",
      "    Multindex: (0, 6, 23084), Value: -0.31019383668899536\n",
      "    Multindex: (0, 6, 29115), Value: -0.2026602178812027\n",
      "    Multindex: (0, 12, 9247), Value: 0.23665377497673035\n",
      "    Multindex: (0, 12, 19133), Value: -0.13597454130649567\n",
      "    Multindex: (0, 13, 1147), Value: 0.10391081869602203\n",
      "    Multindex: (0, 13, 1256), Value: -0.12887312471866608\n",
      "    Multindex: (0, 13, 3385), Value: -0.34761813282966614\n",
      "    Multindex: (0, 13, 3613), Value: -0.11544839292764664\n",
      "    Multindex: (0, 13, 5702), Value: -11.003226280212402\n",
      "    Multindex: (0, 13, 5962), Value: -0.18838448822498322\n",
      "    Multindex: (0, 13, 6959), Value: -0.9820340871810913\n",
      "    Multindex: (0, 13, 15146), Value: -0.12887312471866608\n",
      "    Multindex: (0, 13, 25951), Value: -0.24457168579101562\n",
      "    Multindex: (0, 13, 26640), Value: -0.25634047389030457\n",
      "    Multindex: (0, 13, 27692), Value: -0.12028089165687561\n",
      "    Multindex: (0, 13, 31525), Value: -0.12461315840482712\n",
      "    Multindex: (0, 13, 32650), Value: -0.16245757043361664\n",
      "Layer 1:\n",
      "    Multindex: (0, 6, 588), Value: -0.16466379165649414\n",
      "    Multindex: (0, 13, 245), Value: -0.1918429285287857\n",
      "    Multindex: (0, 13, 303), Value: -0.9617262482643127\n",
      "    Multindex: (0, 13, 614), Value: -0.4203931391239166\n",
      "    Multindex: (0, 13, 639), Value: -0.1067311018705368\n",
      "    Multindex: (0, 13, 1322), Value: -0.11249381303787231\n",
      "    Multindex: (0, 13, 2223), Value: -0.1590975821018219\n",
      "    Multindex: (0, 13, 4875), Value: -0.22198885679244995\n",
      "    Multindex: (0, 13, 7079), Value: -0.1313270777463913\n",
      "    Multindex: (0, 13, 7541), Value: 0.21306736767292023\n",
      "    Multindex: (0, 13, 8150), Value: -0.1918429285287857\n",
      "    Multindex: (0, 13, 9908), Value: -0.13814546167850494\n",
      "    Multindex: (0, 13, 16024), Value: -0.17133969068527222\n",
      "    Multindex: (0, 13, 20331), Value: -1.2441682815551758\n",
      "    Multindex: (0, 13, 23013), Value: -0.18849270045757294\n",
      "    Multindex: (0, 13, 23657), Value: -0.12274052947759628\n",
      "    Multindex: (0, 13, 25848), Value: -0.3059385120868683\n",
      "    Multindex: (0, 13, 29820), Value: -0.1918429285287857\n",
      "    Multindex: (0, 13, 30623), Value: 0.18556568026542664\n",
      "    Multindex: (0, 13, 31453), Value: -0.3648081123828888\n",
      "Layer 2:\n",
      "    Multindex: (0, 13, 5121), Value: -0.16367250680923462\n",
      "    Multindex: (0, 13, 7140), Value: -0.178150936961174\n",
      "    Multindex: (0, 13, 8271), Value: -0.16367250680923462\n",
      "    Multindex: (0, 13, 17322), Value: -0.6946452260017395\n",
      "    Multindex: (0, 13, 19819), Value: -0.10428597778081894\n",
      "    Multindex: (0, 13, 20536), Value: -0.16367250680923462\n",
      "    Multindex: (0, 13, 23880), Value: 0.10106822103261948\n",
      "    Multindex: (0, 13, 24445), Value: -0.15478013455867767\n",
      "    Multindex: (0, 13, 25117), Value: -0.3223865330219269\n",
      "    Multindex: (0, 13, 26060), Value: 0.19325946271419525\n",
      "    Multindex: (0, 13, 28532), Value: -0.5902589559555054\n",
      "Layer 3:\n",
      "    Multindex: (0, 13, 1196), Value: -0.14947494864463806\n",
      "    Multindex: (0, 13, 6716), Value: 0.15161971747875214\n",
      "    Multindex: (0, 13, 11808), Value: -0.11084704846143723\n",
      "    Multindex: (0, 13, 18212), Value: -0.1517772376537323\n",
      "    Multindex: (0, 13, 27249), Value: -0.10479556024074554\n",
      "    Multindex: (0, 13, 27731), Value: 0.16034795343875885\n",
      "    Multindex: (0, 13, 28315), Value: -0.24731893837451935\n",
      "    Multindex: (0, 13, 28765), Value: -0.15697763860225677\n",
      "    Multindex: (0, 13, 31665), Value: -0.19916509091854095\n",
      "Layer 4:\n",
      "    Multindex: (0, 6, 11587), Value: -0.5147899985313416\n",
      "    Multindex: (0, 6, 25244), Value: -2.2249109745025635\n",
      "    Multindex: (0, 13, 11113), Value: -0.12203294783830643\n",
      "    Multindex: (0, 13, 22504), Value: -0.1502879410982132\n",
      "    Multindex: (0, 13, 23022), Value: -0.873496949672699\n",
      "    Multindex: (0, 13, 28362), Value: -0.30438944697380066\n",
      "    Multindex: (0, 13, 29638), Value: -0.2694805860519409\n",
      "    Multindex: (0, 13, 30628), Value: -13.042832374572754\n",
      "    Multindex: (0, 13, 32682), Value: -0.17399896681308746\n",
      "Layer 5:\n",
      "    Multindex: (0, 13, 10300), Value: -0.1266690045595169\n",
      "    Multindex: (0, 13, 17180), Value: -0.29111361503601074\n",
      "    Multindex: (0, 13, 19002), Value: -0.29111361503601074\n",
      "    Multindex: (0, 13, 20568), Value: -0.4593691825866699\n",
      "    Multindex: (0, 13, 29711), Value: -0.10204741358757019\n",
      "    Multindex: (0, 13, 32550), Value: -0.10581643134355545\n",
      "Layer 6:\n",
      "    Multindex: (0, 13, 11804), Value: 0.2141132354736328\n",
      "Layer 7:\n"
     ]
    }
   ],
   "source": [
    "effects, total_effect = out\n",
    "print(f\"Total effect: {total_effect}\")\n",
    "for layer, submodule in enumerate(submodules):\n",
    "    print(f\"Layer {layer}:\")\n",
    "    effect = effects[submodule]\n",
    "    for feature_idx in t.nonzero(effect):\n",
    "        value = effect[tuple(feature_idx)]\n",
    "        if value.abs() > 0.1:\n",
    "            print(f\"    Multindex: {tuple(feature_idx.tolist())}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: All\n",
      "1:  gr\n",
      "2: ands\n",
      "3: ons\n",
      "4:  do\n",
      "5:  resemble\n",
      "6:  the\n",
      "7:  print\n",
      "8:  and\n",
      "9:  De\n",
      "10: bra\n",
      "11:  is\n",
      "12:  an\n",
      "13:  organized\n",
      "14:  child\n",
      "15: .\n"
     ]
    }
   ],
   "source": [
    "for i, tok in enumerate(invoker.input.input_ids[0]):\n",
    "    print(f\"{i}: {model.tokenizer.decode([tok])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_ablate = {\n",
    "#     submodules[0] : [\n",
    "#         5650,\n",
    "#         17126,\n",
    "#         22182,\n",
    "#         25864,\n",
    "#         2655,\n",
    "#         12249,\n",
    "#         12267,\n",
    "#         21248,\n",
    "#         21329,\n",
    "#     ],\n",
    "#     submodules[1] : [\n",
    "#         14465,\n",
    "#         18471,\n",
    "#         22990,\n",
    "#         16629,\n",
    "#         26134,\n",
    "#         32267,\n",
    "#     ],\n",
    "#     submodules[2] : [\n",
    "#         16421,\n",
    "#         22968,\n",
    "#         27888,\n",
    "#         15899,\n",
    "#         28262,\n",
    "#         28306,\n",
    "#         32164,\n",
    "#     ]\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
