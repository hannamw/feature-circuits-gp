{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating circuit quality\n",
    "\n",
    "##### Effect of circuit size on quality metrics\n",
    "- Dataset: Type of circuit (grammar, context, bigram)\n",
    "    - grammar: RC dataset\n",
    "    - context: BiB datset\n",
    "    - bigram: cluster with bigrams\n",
    "- Dataset size (number od samples being averaged on)\n",
    "\n",
    "- Thresholds: Circuit size\n",
    "    - Node \n",
    "    - Edge\n",
    "\n",
    "##### Which type of nodes are significantly discovered best, worst?\n",
    "- model region (layer depth; layer type)\n",
    "\n",
    "Restrictions:\n",
    "- layer_type: attn, mlp, resid (no embeddings)\n",
    "\n",
    "##### What part of the ground truth are we missing?\n",
    "- tracr\n",
    "- **model perplexity after ablating circuit**\n",
    "\n",
    "##### Metrics:\n",
    "- Faithfulness:\n",
    "    1.  (F(C) - F(∅)) / (F(M) - F(∅))\n",
    "    2.  |F(C) - F(M)|\n",
    "\n",
    "- Completeness:\n",
    "    1. |F(∅) - F(M \\ C)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/can/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/can/.local/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/can/.local/lib/python3.8/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/can/dictionary-circuits')\n",
    "from ablation_sam import run_with_ablations\n",
    "import torch as t\n",
    "from argparse import ArgumentParser\n",
    "from nnsight import LanguageModel\n",
    "from dictionary_learning import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map='cuda:0', dispatch=True)\n",
    "\n",
    "\n",
    "# submodules = \\\n",
    "#     [layer.attention for layer in model.gpt_neox.layers] + \\\n",
    "#     [layer.mlp for layer in model.gpt_neox.layers] + \\\n",
    "#     [layer for layer in model.gpt_neox.layers]\n",
    "\n",
    "submodules = [model.gpt_neox.embed_in] + \\\n",
    "    [layer.attention for layer in model.gpt_neox.layers] + \\\n",
    "    [layer.mlp for layer in model.gpt_neox.layers] + \\\n",
    "    [layer for layer in model.gpt_neox.layers]\n",
    "dictionaries = {}\n",
    "ae = AutoEncoder(512, 64 * 512).to('cuda:0')\n",
    "ae.load_state_dict(t.load('/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/embed/10_32768/ae.pt'))\n",
    "dictionaries[model.gpt_neox.embed_in] = ae\n",
    "for i in range(len(model.gpt_neox.layers)):\n",
    "    ae = AutoEncoder(512, 64 * 512).to('cuda:0')\n",
    "    ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/attn_out_layer{i}/10_32768/ae.pt'))\n",
    "    dictionaries[model.gpt_neox.layers[i].attention] = ae\n",
    "\n",
    "    ae = AutoEncoder(512, 64 * 512).to('cuda:0')\n",
    "    ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/mlp_out_layer{i}/10_32768/ae.pt'))\n",
    "    dictionaries[model.gpt_neox.layers[i].mlp] = ae\n",
    "\n",
    "    ae = AutoEncoder(512, 64 * 512).to('cuda:0')\n",
    "    ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/resid_out_layer{i}/10_32768/ae.pt'))\n",
    "    dictionaries[model.gpt_neox.layers[i]] = ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "ablation = \"resample\"\n",
    "circuit_name = \"lin_effects_final-5-pos_nsamples8192_nctx64_cluster50of750_dict10_node0.1_edge0.01_n4_aggsum.pt\"\n",
    "faithfulness = True\n",
    "completeness = True\n",
    "handle_resids = \"default\"\n",
    "\n",
    "# parser = ArgumentParser()\n",
    "# parser.add_argument('--threshold', type=float, default=0.1)\n",
    "# parser.add_argument('--ablation', type=str, default='resample')\n",
    "# parser.add_argument('--circuit', type=str, default='rc_dict10_node0.01_edge0.001_n30_aggsum.pt')\n",
    "# parser.add_argument('--faithfulness', action='store_true')\n",
    "# parser.add_argument('--completeness', action='store_true')\n",
    "# parser.add_argument('--handle_resids', type=str, default='default')\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = t.load(f'/home/can/dictionary-circuits/circuits/{circuit_name}')\n",
    "\n",
    "examples = circuit['examples']\n",
    "\n",
    "nodes_out = circuit['nodes']\n",
    "nodes = {}\n",
    "submod_nodes = (nodes_out['embed'] > threshold).nonzero().squeeze(-1)\n",
    "nodes[model.gpt_neox.embed_in] = list(submod_nodes.act) + (['res'] if len(submod_nodes.resc) > 0 else [])\n",
    "for i in range(len(model.gpt_neox.layers)):\n",
    "    submod_nodes = (nodes_out[f'attn_{i}'] > threshold).nonzero().squeeze(-1)\n",
    "    nodes[model.gpt_neox.layers[i].attention] = list(submod_nodes.act) + (['res'] if len(submod_nodes.resc) > 0 else [])\n",
    "    submod_nodes = (nodes_out[f'mlp_{i}'] > threshold).nonzero().squeeze(-1)\n",
    "    nodes[model.gpt_neox.layers[i].mlp] = list(submod_nodes.act) + (['res'] if len(submod_nodes.resc) > 0 else [])\n",
    "    submod_nodes = (nodes_out[f'resid_{i}'] > threshold).nonzero().squeeze(-1)\n",
    "    nodes[model.gpt_neox.layers[i]] = list(submod_nodes.act) + (['res'] if len(submod_nodes.resc) > 0 else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'patch_prefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m clean_inputs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mcat([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m clean_answer_idxs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtensor([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_answer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples], dtype\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m patch_inputs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mcat([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m patch_answer_idxs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtensor([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch_answer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples], dtype\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetric_fn\u001b[39m(model):\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m clean_inputs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mcat([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m clean_answer_idxs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtensor([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_answer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples], dtype\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m patch_inputs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mcat([\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatch_prefix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m patch_answer_idxs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtensor([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch_answer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples], dtype\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetric_fn\u001b[39m(model):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'patch_prefix'"
     ]
    }
   ],
   "source": [
    "clean_inputs = t.cat([e['clean_prefix'] for e in examples], dim=0).to('cuda:0')\n",
    "clean_answer_idxs = t.tensor([e['clean_answer'] for e in examples], dtype=t.long, device='cuda:0')\n",
    "patch_inputs = t.cat([e['patch_prefix'] for e in examples], dim=0).to('cuda:0')\n",
    "patch_answer_idxs = t.tensor([e['patch_answer'] for e in examples], dtype=t.long, device='cuda:0')\n",
    "def metric_fn(model):\n",
    "    return (\n",
    "        - t.gather(model.embed_out.output[:,-1,:], dim=-1, index=patch_answer_idxs.view(-1, 1)).squeeze(-1) + \\\n",
    "        t.gather(model.embed_out.output[:,-1,:], dim=-1, index=clean_answer_idxs.view(-1, 1)).squeeze(-1)\n",
    "    )\n",
    "\n",
    "if ablation == 'resample': ablation_fn = lambda x: x\n",
    "if ablation == 'zero': ablation_fn = lambda x: x.zeros_like()\n",
    "if ablation == 'mean': ablation_fn = lambda x: x.mean(dim=0).expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Faithfulness\n",
    "ablation_outs = run_with_ablations(\n",
    "    clean_inputs,\n",
    "    patch_inputs,\n",
    "    model,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    nodes,\n",
    "    metric_fn,\n",
    "    ablation_fn=ablation_fn,\n",
    "    handle_resids=handle_resids\n",
    ")\n",
    "print(f\"F(C) = {ablation_outs.mean()}\")\n",
    "\n",
    "with model.trace(clean_inputs):\n",
    "    metric = metric_fn(model).save()\n",
    "normal_outs = metric.value\n",
    "print(f\"F(M) = {normal_outs.mean()}\")\n",
    "\n",
    "all_ablated = run_with_ablations(\n",
    "    clean_inputs,\n",
    "    patch_inputs,\n",
    "    model,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    nodes={submod : [] for submod in submodules},\n",
    "    metric_fn=metric_fn,\n",
    "    ablation_fn=ablation_fn,\n",
    "    handle_resids=handle_resids\n",
    ")\n",
    "print(f\"F(∅) = {all_ablated.mean()}\")\n",
    "\n",
    "print(f\"|F(C) - F(M)| = {(ablation_outs - normal_outs).abs().mean()}\")\n",
    "print(f\"|F(∅) - F(M)| = {(all_ablated - normal_outs).abs().mean()}\")\n",
    "\n",
    "print(normal_outs - ablation_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completeness\n",
    "\n",
    "ablation_outs = run_with_ablations(\n",
    "        clean_inputs,\n",
    "        patch_inputs,\n",
    "        model,\n",
    "        submodules,\n",
    "        dictionaries,\n",
    "        nodes,\n",
    "        metric_fn,\n",
    "        complement=True,\n",
    "        ablation_fn=ablation_fn,\n",
    "        handle_resids=handle_resids\n",
    "    )\n",
    "    print(f\"F(M \\ C) = {ablation_outs.mean()}\")\n",
    "    print(f'|F(∅) - F(M \\ C)| = {(all_ablated - ablation_outs).abs().mean()}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(f\"Completeness: {(all_ablated - ablation_outs).abs().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
