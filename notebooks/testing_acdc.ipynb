{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing patching functions in acdc.py\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/can/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import zstandard as zstd\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from einops import rearrange\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "from dictionary_learning.buffer import ActivationBuffer\n",
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "from dictionary_learning.training import trainSAE\n",
    "from acdc import patching_on_y, patching_on_downstream_feature\n",
    "from loading_utils import DictionaryCfg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from circuitsvis.activations import text_neuron_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "ACTIVATION_DIM = 512\n",
    "DICTIONARY_SIZE = 64 * ACTIVATION_DIM # This is the dict_size sam mostly works with.\n",
    "EPS = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Model and SAEs\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map='cuda:0')\n",
    "submodules = [\n",
    "    layer.mlp for layer in model.gpt_neox.layers\n",
    "]\n",
    "submodule_name_generic = 'model.gpt_neox.layers.{}.mlp.dense_4h_to_h'\n",
    "submodule_names = [submodule_name_generic.format(str(layer)) for layer in range(model.config.num_hidden_layers)]\n",
    "\n",
    "dictionaries = []\n",
    "for i in range(len(submodules)):\n",
    "    dictionary = AutoEncoder(ACTIVATION_DIM, DICTIONARY_SIZE).to('cuda:0')\n",
    "    dictionary.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/mlp_out_layer{i}/1_32768/ae.pt'))\n",
    "    dictionaries.append(dictionary)\n",
    "\n",
    "dict_cfg = DictionaryCfg(\n",
    "    dictionary_dir='/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/',\n",
    "    dictionary_size=32768\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([510, 637])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy dataset for the \"Plural\" task\n",
    "\n",
    "plural_token_pos = 1\n",
    "tok = lambda x: t.tensor(model.tokenizer.encode(x))\n",
    "toy_dataset = [dict(\n",
    "    clean_prefix=tok(\"The man\"),\n",
    "    clean_answer=tok(\" is\"),\n",
    "    patch_prefix=tok(\"The men\"),\n",
    "    patch_answer=tok(\" are\"),\n",
    "    prefix_length_wo_pad=tok(\"The man\").shape[-1],\n",
    ")]\n",
    "\n",
    "toy_dataset[0]['clean_prefix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diverse dataset for Circuitvis evaluation\n",
    "\n",
    "# set up data as a generator\n",
    "data_path = '/share/data/datasets/pile/the-eye.eu/public/AI/pile/train/00.jsonl.zst'\n",
    "compressed_file = open(data_path, 'rb')\n",
    "dctx = zstd.ZstdDecompressor()\n",
    "reader = dctx.stream_reader(compressed_file)\n",
    "text_stream = io.TextIOWrapper(reader, encoding='utf-8')\n",
    "def generator():\n",
    "    for line in text_stream:\n",
    "        yield json.loads(line)['text']\n",
    "data = generator()\n",
    "\n",
    "# Buffer tied to one specific submodule!\n",
    "buffer = ActivationBuffer(\n",
    "    data,\n",
    "    model,\n",
    "    submodules[0], # we only use data from the buffer, not acttivations. Thus we can pass any submodule here\n",
    "    io='out',\n",
    "    in_feats=ACTIVATION_DIM,\n",
    "    out_feats=ACTIVATION_DIM,\n",
    "    in_batch_size=512,\n",
    "    out_batch_size=2 ** 15,\n",
    "    n_ctxs=1e4,\n",
    ")\n",
    "\n",
    "tokenized_prompts = buffer.tokenized_batch(batch_size=512) # [batch, n_ctx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circuitsvis visualization\n",
    "\n",
    "def get_feature_activations(layer):\n",
    "    '''\n",
    "    Function for retrieving feature activations from tokenized batch\n",
    "    returns activations for all submodules, dictionaries if layer == None\n",
    "    \n",
    "    '''\n",
    "    with model.generate(max_new_tokens=1, pad_token_id=model.tokenizer.pad_token_id) as generator:\n",
    "        with generator.invoke(tokenized_prompts['input_ids'], scan=False) as invoker:\n",
    "            hidden_states = submodules[layer].output.save() # hidden_states.value: [batch, n_ctx, d_mlp]\n",
    "    dictionary_activation = dictionaries[layer].encode(hidden_states.value)\n",
    "    return dictionary_activation\n",
    "\n",
    "def list_decode(x):\n",
    "    if isinstance(x, int):\n",
    "        return model.tokenizer.decode(x)\n",
    "    else:\n",
    "        return [list_decode(y) for y in x]\n",
    "    \n",
    "def topk_prompts_provider(feature_layer: int, feature_id: int, k: int = 30):\n",
    "    # Sort examples in batch by max feature activation\n",
    "    dictionary_activations = get_feature_activations(feature_layer)\n",
    "    acts = dictionary_activations[:, :, feature_id].cpu() # acts: [batch, pos]\n",
    "    flattened_acts = rearrange(acts, 'b l -> (b l)')\n",
    "    topk_indices = t.argsort(flattened_acts, dim=0, descending=True)[:k] \n",
    "    batch_indices = topk_indices // acts.shape[1]\n",
    "    token_indices = topk_indices % acts.shape[1]\n",
    "\n",
    "    # Visualize\n",
    "    tokens = [\n",
    "    tokenized_prompts['input_ids'][batch_idx, :token_idx+1].tolist() for batch_idx, token_idx in zip(batch_indices, token_indices)\n",
    "    ]\n",
    "    tokens = list_decode(tokens)\n",
    "    activations = [\n",
    "        acts[batch_idx, :token_id+1, None, None] for batch_idx, token_id in zip(batch_indices, token_indices)\n",
    "    ]\n",
    "    return tokens, activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `patching_on_y`\n",
    "Evaluate causal effects of features in layer 5 on the logit diff between clean and patch answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_patching_on_y = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total metric diff after replacing clean prefix with patch prefix: 8.802978515625\n"
     ]
    }
   ],
   "source": [
    "effects_on_y, total_effect_on_y = patching_on_y(\n",
    "    toy_dataset,\n",
    "    model,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    method='all-folded'\n",
    ")\n",
    "\n",
    "print(f'total metric diff after replacing clean prefix with patch prefix: {total_effect_on_y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features in layer 5 with highest impact on logit diff\n",
      "feat 22167:\t 0.15118573606014252\n",
      "feat 7352:\t 0.08815076947212219\n",
      "feat 10880:\t 0.07269265502691269\n",
      "feat 14747:\t 0.06640410423278809\n",
      "feat 13505:\t 0.05375923216342926\n",
      "feat 19033:\t 0.023533709347248077\n",
      "feat 20780:\t 0.022761814296245575\n",
      "feat 30204:\t 0.013442937284708023\n",
      "feat 5580:\t 0.012757628224790096\n",
      "feat 25775:\t 0.011507045477628708\n"
     ]
    }
   ],
   "source": [
    "# Top 10 features in layer `layer_patching_on_y` with highest impact on logit diff\n",
    "\n",
    "# Only effect on token position `plural_token_pos` matters for \"Plurals\" task\n",
    "effects_on_y = effects_on_y[submodules[layer_patching_on_y]][plural_token_pos].detach().cpu()\n",
    "top_effects_on_y = t.argsort(effects_on_y, descending=True)[:10]\n",
    "top_features_on_y = []\n",
    "print(f'Top 10 features in layer {layer_patching_on_y} with highest impact on logit diff')\n",
    "for i in top_effects_on_y:\n",
    "    top_features_on_y.append(i)\n",
    "    print(f'feat {i}:\\t {effects_on_y[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(effects_on_y[effects_on_y.abs() > EPS], bins=100)\n",
    "plt.xscale('log')\n",
    "plt.title(f'Feature effect on logit diff distribution\\nMLP={layer_patching_on_y}');\n",
    "plt.xlabel('Mean feature activation')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-cc7f0e07-61d5\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-cc7f0e07-61d5\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [[\"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"View\", \" Transcript\", \"\\n\", \"\\n\", \"Trans\", \"cript\", \"\\n\", \"\\n\", \"W\", \"ally\", \" The\", \" Econom\", \"ist\", \".\", \" Dil\", \"bert\", \":\", \" I\", \" wonder\", \" if\", \" you\", \"'ll\", \" win\", \" the\", \" Nobel\", \" Prize\", \" for\", \" Economics\", \".\", \" Man\"], [\"Eight\", \" months\", \" before\", \" their\", \" company\", \"'s\", \" 20\", \"th\", \" birthday\", \",\", \" Cow\", \"girl\", \" Cream\", \"ery\", \" owners\", \" Sue\", \" Con\", \"ley\", \" and\", \" Peggy\", \" Smith\", \" have\", \" sold\", \" their\", \" nationally\", \" distributed\", \" cheese\", \" business\", \" to\", \" a\", \" larger\", \" Swiss\", \" dairy\", \" company\", \",\", \" Emm\", \"i\", \",\", \" which\", \" six\", \" months\", \" ago\", \" also\", \" bought\", \" up\", \" Sebast\", \"opol\", \" goat\", \" dairy\", \" farm\", \" Red\", \"wood\", \" Hills\", \" Farm\", \" and\", \" Cream\", \"ery\", \".\", \"\\n\", \"\\n\", \"\\\"\", \"We\", \" felt\", \" with\", \" great\", \" confidence\", \" that\", \" we\", \" have\", \" found\", \" a\", \" like\", \"-\", \"minded\", \",\", \" value\", \"-\", \"aligned\", \" partner\", \" in\", \" Emm\", \"i\", \",\\\"\", \" the\", \" duo\", \" wrote\", \" in\", \" a\", \" Facebook\", \" post\", \" announcing\", \" the\", \" move\", \",\", \" which\", \" was\", \" initially\", \" reported\", \" by\", \" the\", \" Chronicle\", \".\", \"\\n\", \"\\n\", \"The\", \" deal\", \" comes\", \" along\", \" with\", \" Tom\"], [\"But\", \" something\", \" is\", \" happening\", \" here\", \" and\", \" you\", \" don\", \"\\u2019\", \"t\", \" know\", \" what\", \" it\", \" is\", \"\\n\", \"\\n\", \"Do\", \" you\", \",\", \" Mr\", \",\", \" Jones\", \"?\", \" (\", \"Bob\", \" Dylan\", \",\", \" 1965\", \")\", \"\\n\", \"\\n\", \"R\", \"ul\", \"ers\", \" seldom\", \" know\", \" what\", \"\\u2019\", \"s\", \" happening\", \",\", \" do\", \" they\", \"?\", \" They\", \" have\", \" the\", \" intelligence\", \" apparatus\", \" and\", \" their\", \" party\", \" polit\", \"icos\", \" feeding\", \" them\", \" whatever\", \" the\", \" powerful\", \" like\", \" to\", \" hear\", \",\", \" but\", \" the\", \" assessment\", \" of\", \" the\", \" people\", \" can\", \" be\", \" in\", \" delicious\", \" discord\", \".\", \"\\n\", \"\\n\", \"At\", \"al\", \" B\", \"ih\", \"ari\", \" V\", \"aj\", \"pay\", \"ee\", \" ordered\", \" elections\", \" early\", \" because\", \" his\", \" India\", \" was\", \" shining\", \".\", \" He\", \" paid\", \" the\", \" price\", \".\", \" Through\", \" cries\", \" of\", \" policy\", \" paralysis\", \" and\", \" corruption\", \",\", \" Man\"], [\"H\", \"ONG\", \" K\", \"ONG\", \" \\u2014\", \" July\", \" 4\", \"th\", \" may\", \" be\", \" a\", \" holiday\", \" for\", \" Americans\", \",\", \" but\", \" in\", \" China\", \" it\", \" is\", \" the\", \" eve\", \" of\", \" nationwide\", \" release\", \" of\", \" \\u201c\", \"Man\"], [\"Follow\", \" Us\", \"\\n\", \"\\n\", \"Tim\"], [\"Man\", \"hattan\", \" Airport\", \" Foundation\", \"\\n\", \"\\n\", \"The\", \" Manhattan\", \" Airport\", \" Foundation\", \" is\", \" a\", \" par\", \"ody\", \" advocacy\", \" organization\", \" lobbying\", \",\", \" as\", \" part\", \" of\", \" a\", \" ho\", \"ax\", \",\", \" for\", \" the\", \" development\", \" of\", \" an\", \" international\", \" airport\", \" replacing\", \" Central\", \" Park\", \" between\", \" 59\", \"th\", \" Street\", \" and\", \" 110\", \"th\", \" Street\", \" in\", \" Manhattan\", \".\", \" The\", \" Foundation\", \" claims\", \" to\", \" have\", \" been\", \" founded\", \" in\", \" 2006\", \" and\", \" that\", \" it\", \" is\", \" composed\", \" of\", \" members\", \" of\", \" civic\", \",\", \" environmental\", \" and\", \" community\", \" groups\", \" as\", \" well\", \" as\", \" elected\", \" officials\", \" and\", \" city\", \" and\", \" state\", \" agencies\", \".\", \"\\n\", \"\\n\", \"The\", \" Foundation\", \" states\", \" that\", \" their\", \" proposed\", \" '\", \"Man\"], [\"Education\", \" Week\", \" reporter\", \" Ben\"], [\"It\", \"\\u2019\", \"s\", \" a\", \" crime\", \" so\", \" horrible\", \" that\", \" it\", \"\\u2019\", \"s\", \" hard\", \" to\", \" imagine\", \".\", \" On\", \" Thursday\", \",\", \" a\", \" man\", \" in\", \" C\", \"ang\", \"gu\", \" cut\", \" off\", \" his\", \" wife\", \"\\u2019\", \"s\", \" left\", \" foot\", \" and\", \" attempted\", \" to\", \" cle\", \"ave\", \" off\", \" her\", \" right\", \" foot\", \" as\", \" well\", \".\", \" The\", \" attack\", \" occurred\", \" in\", \" front\", \" of\", \" the\", \" couple\", \"\\u2019\", \"s\", \" young\", \" children\", \",\", \" who\", \" have\", \" now\", \" been\", \" sent\", \" to\", \" their\", \" grandmother\", \" in\", \" Sing\"], [\"L\", \"uck\", \"now\", \",\", \" Nov\", \" 7\", \":\", \" Ay\", \"od\", \"hy\", \"a\", \" Deep\", \"ost\", \"av\", \" 2018\", \",\", \" an\", \" event\", \" organised\", \" to\", \" mark\", \" Di\", \"w\", \"ali\", \" celebrations\", \" in\", \" Ay\", \"od\", \"hy\", \"a\", \" town\", \" -\", \" has\", \" entered\", \" Gu\", \"in\", \"ness\", \" Book\", \" of\", \" World\", \" Records\", \" on\", \" Tuesday\", \".\", \" A\", \" Gu\", \"in\", \"ness\", \" certificate\", \" was\", \" issued\", \" to\", \" UP\", \" government\", \"'s\", \" tourism\", \" department\", \" and\", \" Dr\", \" Ram\", \" Man\"], [\"My\", \" Hero\", \" Academ\", \"ia\", \" Season\", \" 2\", \"-\", \" Episode\", \" 18\", \"\\n\", \"\\n\", \"After\", \" last\", \" weeks\", \" episode\", \",\", \" I\", \" was\", \" really\", \" curious\", \" what\", \" they\", \" had\", \" in\", \" store\", \" for\", \" us\", \" this\", \" week\", \".\", \" How\", \" the\", \" heroes\", \" will\", \" come\", \" back\", \" to\", \" Earth\", \" after\", \" such\", \" a\", \" traumatic\", \" experience\", \".\", \" And\", \" good\", \" thing\", \" for\", \" us\", \",\", \" this\", \" episode\", \" is\", \" rightly\", \" named\", \" \\u201c\", \"The\", \" After\", \"math\", \" of\", \" Hero\", \" K\", \"iller\", \":\", \" St\", \"ain\", \"\\u201d.\", \"\\n\", \"\\n\", \"My\", \" Hero\", \" Academ\", \"ia\", \"-\", \" Fun\", \"imation\", \"\\n\", \"\\n\", \"We\", \" open\", \" with\", \" Iz\", \"uku\", \",\", \" I\", \"ida\", \",\", \" and\", \" T\", \"odor\", \"oki\", \" all\", \" in\", \" the\", \" hospital\", \".\", \" They\", \" are\", \" all\", \" recovering\", \" from\", \" their\", \" tremendous\", \" fight\", \".\", \" But\", \" also\", \" reflecting\", \" how\", \" lucky\", \" they\", \" are\", \" to\", \" be\", \" alive\", \" still\", \".\", \" The\", \" door\", \" opens\", \" and\", \" we\", \" see\", \" Gran\"], [\"Follow\", \" me\", \" on\", \"\\n\", \"\\n\", \"Thursday\", \",\", \" 29\", \" March\", \" 2012\", \"\\n\", \"\\n\", \"This\", \" is\", \" a\", \" card\", \" I\", \" made\", \" for\", \" my\", \" friend\", \" E\", \"ile\", \"en\", \" who\", \"'s\", \" birthday\", \" it\", \" is\", \" today\", \".....\", \"Happy\", \" Birth\", \"day\", \" E\", \"ile\", \"en\", \"...\", \"I\", \" just\", \" love\", \" this\", \" S\", \".\", \"U\", \".\", \" Elements\", \" of\", \" Style\", \" stamp\", \" set\", \".\", \" Col\", \"oured\", \" with\", \" C\", \"opic\", \" pens\", \" and\", \" I\", \" have\", \" 3\", \"D\", \" some\", \" of\", \" the\", \" flowers\", \".\", \"Card\", \",\", \" papers\", \" and\", \" the\", \" emb\", \"oss\", \"ing\", \" folder\", \" are\", \" all\", \" from\", \" St\", \"amp\", \"in\", \" Up\", \"...\", \"just\", \" added\", \" a\", \" touch\", \" of\", \" gl\", \"it\", \"tered\", \" lace\", \" and\", \" a\", \" few\", \" pear\", \"ls\", \".\", \"\\n\", \"\\n\", \"Saturday\", \",\", \" 24\", \" March\", \" 2012\", \"\\n\", \"\\n\", \"This\", \" is\", \" an\", \" image\", \" from\", \" the\", \" Oh\"], [\"\\\"\", \"K\", \"ids\", \",\", \" on\", \" my\", \" first\", \" day\", \" as\", \" a\", \" college\", \" professor\", \",\", \" there\", \" re\", \" two\", \" things\", \" I\", \" didn\", \"'t\", \" know\", \" that\", \" I\", \" wish\", \" did\", \".\\\"\", \" \\\"\", \"The\", \" first\", \" thing\", \" was\", \" that\", \" your\", \" mother\", \" was\", \" in\", \" that\", \" classroom\", \".\\\"\", \" \\\"\", \"The\", \" second\", \" thing\", \"?\\\"\", \" \\\"\", \"Well\", \",\", \" to\", \" explain\", \" tt\", \",\", \" we\", \" have\", \" to\", \" go\", \" back\", \" to\", \" the\", \" beginning\", \" of\", \" the\", \" summer\", \",\", \" when\", \",\", \" after\", \" a\", \" year\", \" of\", \" wrestling\", \" with\", \" their\", \" feelings\", \" for\", \" each\", \" other\", \",\\\"\", \" \\\"\", \"Bar\"], [\"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"Rob\", \"ins\", \"ons\", \" ready\", \" to\", \" roll\", \"\\n\", \"\\n\", \"Tw\", \"ins\", \" Ty\", \"rell\", \" and\", \" Ty\", \"ree\", \" Robinson\", \" making\", \" their\", \" marks\", \" in\", \" football\", \",\", \" basketball\", \"\\n\", \"\\n\", \"A\", \" quick\", \" look\", \" at\", \" twin\", \" brothers\", \" Ty\", \"ree\", \" and\", \" Ty\", \"rell\", \" Robinson\", \" (\", \"San\"], [\"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"Kevin\", \" Os\", \"borne\", \",\", \" the\", \" baby\", \"'s\", \" father\", \",\", \" delivered\", \" his\", \" daughter\", \",\", \" who\", \" weighed\", \" 6\", \" pounds\", \" and\", \" 13\", \" ounces\", \".\", \" Crew\", \" members\", \" found\", \" Os\"], [\"The\", \" Ghost\", \"s\", \" of\", \" Flight\", \" 191\", \" Judith\", \" and\", \" She\"], [\"The\", \" b\", \"ant\", \"am\", \"weight\", \" champion\", \" of\", \" D\", \"EEP\", \",\", \" Tak\"], [\"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"Tag\", \":\", \" El\", \"oy\", \" Cas\", \"ados\", \"\\n\", \"\\n\", \"Original\", \" US\", \" release\", \" date\", \":\", \" December\", \" 5\", \",\", \" 2008\", \" Production\", \" budget\", \":\", \" $\", \"25\", \",\", \"000\", \",\", \"000\", \" World\", \"wide\", \" gross\", \":\", \" $\", \"27\", \",\", \"426\", \",\", \"335\", \" There\", \" are\", \" timely\", \" films\", \" and\", \" then\", \" there\", \" are\", \" films\", \" that\", \" are\", \" before\", \" their\", \" time\", \".\", \" Ron\"], [\"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"<|endoftext|>\", \"----------------------\", \" Forward\", \"ed\", \" by\", \" Benjamin\", \" Rogers\", \"/\", \"HOU\", \"/\", \"ECT\", \" on\", \" 10\", \"/\", \"19\", \"/\", \"2000\", \" \", \"\\n\", \"03\", \":\", \"13\", \" PM\", \" ---------------------------\", \"\\n\\n\", \"\\n\", \"D\", \"pl\", \"fl\", \"an\", \"@\", \"a\", \"ol\", \".\", \"com\", \" on\", \" 10\", \"/\", \"18\", \"/\", \"2000\", \" 06\", \":\", \"18\", \":\", \"51\", \" PM\", \"\\n\", \"To\", \":\", \" Benjamin\", \".\", \"Rog\", \"ers\", \"@\", \"enron\", \".\", \"com\", \"\\n\", \"cc\", \":\", \"  \", \"\\n\", \"Subject\", \":\", \" (\", \"no\", \" subject\", \")\", \"\\n\\n\", \"\\n\", \"Ben\"], [\"Chat\", \"S\", \"ua\", \"\\n\", \"\\n\", \"Chat\", \"S\", \"ua\", \" ()\", \" is\", \" a\", \" Thai\", \" film\", \" based\", \" on\", \" a\", \" work\", \" by\", \" \\\"\", \"O\", \"raw\", \"un\", \"\\\"\", \" (\", \"ly\", \"u\", \" S\", \"resa\", \"we\", \"k\", \").\", \" It\", \" was\", \" prem\", \"i\", \"\\u00e8\", \"red\", \" on\", \" June\", \" 18\", \",\", \" 1958\", \",\", \" at\", \" Sal\", \"a\", \" Chal\", \"erm\", \"kr\", \"ung\", \" Royal\", \" Theatre\", \" and\", \" Sal\", \"a\", \" Chal\", \"erm\", \"b\", \"ure\", \" Royal\", \" Theatre\", \".\", \" The\", \" film\", \" was\", \" directed\", \" by\", \" Pr\", \"ate\", \"b\", \" G\", \"omon\", \"p\", \"is\", \".\", \" It\", \" is\", \" a\", \" sequel\", \" to\", \" the\", \" 1956\", \" film\", \" Pra\", \"i\", \"K\", \"uar\", \"ng\", \".\", \"\\n\", \"\\n\", \"The\", \" film\", \" was\", \" the\", \" screen\", \" debut\", \" of\", \" Mit\", \"r\", \" Cha\", \"ib\", \"anch\", \"a\", \",\", \" as\", \" W\", \"ai\", \" S\", \"uk\", \"da\", \",\", \" and\", \" stars\", \" Rew\", \"ade\", \"e\", \" Sew\", \"il\", \"ai\", \",\", \" Win\"], [\"Education\", \" Week\", \" reporter\", \" Ben\", \" Her\", \"old\", \" explores\", \" how\", \" technology\", \" is\", \" shaping\", \" teaching\", \" and\", \" learning\", \" and\", \" the\", \" management\", \" of\", \" schools\", \".\", \" Join\", \" the\", \" discussion\", \" as\", \" he\", \" analy\", \"zes\", \" the\", \" latest\", \" developments\", \".\", \"\\n\", \"\\n\", \"G\", \"ates\", \" Foundation\", \",\", \" Chan\"]], \"activations\": [[[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.12442129850387573]], [[0.0]], [[0.0]], [[0.11521238088607788]], [[0.08617711067199707]], [[0.650688648223877]], [[0.0]], [[0.0]], [[0.0]], [[0.227697491645813]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.6830761432647705]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.18108701705932617]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.03324079513549805]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.408930540084839]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.6206173896789551]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.4015779495239258]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.060173988342285156]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.06329208612442017]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.3145463466644287]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.1805975437164307]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.0856359004974365]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.079663038253784]]], [[[0.0]], [[0.0]], [[0.0]], [[2.0553925037384033]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.45713305473327637]], [[1.2764627933502197]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.043241262435913]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3910926580429077]], [[0.19442355632781982]], [[0.0]], [[0.0]], [[0.15326374769210815]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.9799153804779053]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.2172297239303589]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3445526361465454]], [[0.12494051456451416]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.18480432033538818]], [[0.8056193590164185]], [[1.9138822555541992]]], [[[0.0]], [[0.0]], [[0.06399273872375488]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.25402867794036865]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.003109276294708252]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3105437755584717]], [[0.0]], [[0.0]], [[0.1313149333000183]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.03993505239486694]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.1531212329864502]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.011061549186706543]], [[0.0]], [[0.12569767236709595]], [[0.4424159526824951]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.7976183891296387]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.5084753036499023]], [[0.1856592893600464]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.05351513624191284]], [[0.3524937629699707]], [[0.0]], [[0.4185972213745117]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.14710062742233276]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.14274132251739502]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.7563469409942627]]], [[[0.0]], [[0.2469104528427124]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.5337263345718384]], [[0.0]], [[1.718266487121582]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.13652664422988892]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.28980326652526855]], [[0.27268433570861816]], [[1.0595569610595703]], [[0.0]], [[0.0]], [[0.4931197166442871]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.673927903175354]], [[0.0]], [[0.0011972784996032715]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.6911485195159912]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.2544548511505127]], [[0.0]], [[0.0]], [[0.0]], [[0.46578800678253174]], [[0.0]], [[0.0]], [[0.08627575635910034]], [[0.0]], [[0.0]], [[0.08682775497436523]], [[0.14481514692306519]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.08432883024215698]], [[0.0]], [[0.0]], [[1.589153528213501]]], [[[0.0]], [[0.5119963884353638]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.24826645851135254]], [[0.0]], [[1.5804922580718994]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.5652945041656494]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.2361689805984497]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.5210871696472168]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.3057934045791626]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.29600822925567627]], [[0.1799558401107788]], [[0.0738835334777832]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.5184955596923828]], [[0.0]], [[0.0]], [[0.0]], [[0.3196660280227661]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.5042145252227783]]], [[[0.0]], [[0.07950460910797119]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.1319793462753296]], [[0.6029633283615112]], [[0.2966562509536743]], [[0.0]], [[0.0]], [[0.6229060888290405]], [[0.0]], [[0.0]], [[0.0]], [[0.03153461217880249]], [[0.10227864980697632]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.0034838914871216]], [[0.0]], [[0.38598108291625977]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.2719036340713501]], [[0.0]], [[0.0]], [[0.0]], [[0.10639750957489014]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7895808219909668]], [[0.6974588632583618]], [[0.0]], [[0.0]], [[0.1823207139968872]], [[0.14763975143432617]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.9238052368164062]], [[0.39003753662109375]], [[1.1302043199539185]], [[0.0]], [[0.0175209641456604]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.3792550563812256]], [[0.6123752593994141]], [[1.2417423725128174]], [[0.6742204427719116]], [[0.25118768215179443]], [[0.0]], [[0.0]], [[0.0]], [[0.3480645418167114]], [[0.707633376121521]], [[0.12168937921524048]], [[1.0812567472457886]], [[0.0]], [[0.0]], [[0.0]], [[0.058240413665771484]], [[1.0680856704711914]], [[0.22147417068481445]], [[0.0]], [[1.3246605396270752]], [[0.0]], [[0.0]], [[0.0]], [[1.49149751663208]]], [[[0.0]], [[0.0]], [[0.0]], [[2.0553925037384033]], [[0.10629314184188843]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.4637677669525146]]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fde073aa8b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to stack functions to display circuitvis properly\n",
    "text_neuron_activations(\n",
    "    *topk_prompts_provider(\n",
    "        feature_layer=layer_patching_on_y, \n",
    "        feature_id=8011,\n",
    "        k=20\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/22167 seems to activate on singular nouns related do people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `patching_on_downstream_feature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_feat_layer = 5\n",
    "downstream_feat_id = 22167\n",
    "\n",
    "k_upstream_feats = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total metric diff after replacing clean prefix with patch prefix: -2.3897130489349365\n"
     ]
    }
   ],
   "source": [
    "effects_on_dsfeat, total_effect_on_dsfeat = patching_on_downstream_feature(\n",
    "    toy_dataset,\n",
    "    model,\n",
    "    upstream_submodules=submodules[:downstream_feat_layer],\n",
    "    upstream_dictionaries=dictionaries[:downstream_feat_layer],\n",
    "    downstream_submodule=submodules[downstream_feat_layer],\n",
    "    downstream_dictionary=dictionaries[downstream_feat_layer],\n",
    "    downstream_feature_id=downstream_feat_id,\n",
    "    method='separate'\n",
    ")\n",
    "\n",
    "print(f'total metric diff after replacing clean prefix with patch prefix: {total_effect_on_dsfeat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 features per layer with highest impact on downstream feat activation\n",
      "\n",
      "Layer 0:\n",
      "feat 21840:\t 0.0\n",
      "feat 21855:\t 0.0\n",
      "feat 21854:\t 0.0\n",
      "\n",
      "Layer 1:\n",
      "feat 14400:\t 0.030630111694335938\n",
      "feat 25045:\t 0.009372711181640625\n",
      "feat 10964:\t 0.006834506988525391\n",
      "\n",
      "Layer 2:\n",
      "feat 12654:\t 0.029448509216308594\n",
      "feat 27186:\t 0.018366336822509766\n",
      "feat 13579:\t 0.009025096893310547\n",
      "\n",
      "Layer 3:\n",
      "feat 26928:\t 0.03757333755493164\n",
      "feat 20945:\t 0.03383207321166992\n",
      "feat 17355:\t 0.03262805938720703\n",
      "\n",
      "Layer 4:\n",
      "feat 2871:\t 0.12388277053833008\n",
      "feat 11028:\t 0.004107952117919922\n",
      "feat 9616:\t 0.0036187171936035156\n"
     ]
    }
   ],
   "source": [
    "# Top k features per layer with highest impact on downstream feat activation\n",
    "\n",
    "topk_upstream_feats = t.zeros((len(submodules), k_upstream_feats), dtype=int)\n",
    "print(f'Top {k_upstream_feats} features per layer with highest impact on downstream feat activation')\n",
    "\n",
    "for layer in range(len(submodules)-1):\n",
    "    print(f'\\nLayer {layer}:')\n",
    "    effects_on_dsfeat_per_layer = effects_on_dsfeat[submodule_names[layer]][plural_token_pos].detach().cpu() # Only effect on token position `plural_token_pos` matters for \"Plurals\" task\n",
    "    topk_upstream_feats[layer] = t.argsort(effects_on_dsfeat_per_layer, descending=True)[:k_upstream_feats]\n",
    "    for i in topk_upstream_feats[layer]:\n",
    "        print(f'feat {i}:\\t {effects_on_dsfeat_per_layer[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 1 features per layer found seem to be related to the plurals task!\n",
    "\n",
    "Values in same or later layer are generally uninterpretable.\n",
    "I expect that, xact patching should yield 0 unconnected features in same or later layer. (No bwdpass involved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-6b1aa1d6-bebd\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-6b1aa1d6-bebd\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [[\"Ben\", \"jamin\", \" Lok\", \" describes\", \" how\", \" the\", \" robot\", \" butt\", \" sensors\", \" work\", \" 2\", \":\", \"26\", \"\\n\", \"\\n\", \"Pro\", \"state\", \" exams\", \" are\", \" potentially\", \"-\", \"life\", \" saving\", \".\", \" But\", \" the\", \" process\", \" of\", \" getting\", \" one\", \" can\", \" be\", \" nerve\", \"-\", \"r\", \"acking\", \" \\u2014\", \" both\", \" for\", \" the\", \" doctor\", \" and\", \" the\", \" patient\", \".\", \"\\n\", \"\\n\", \"A\", \" group\", \" of\", \" scientists\", \" from\", \" D\", \"rex\", \"el\", \" University\", \" and\", \" the\", \" Univers\", \"ities\", \" of\", \" Wisconsin\", \" and\", \" Florida\", \" are\", \" hoping\", \" to\", \" assist\", \" with\", \" that\", \".\", \" They\", \"'ve\", \" designed\", \" a\", \" robot\", \" to\", \" help\", \" medical\", \" students\"], [\"Common\", \"wealth\", \" Bank\", \" and\", \" the\", \" Australian\", \" Chamber\", \" Orchestra\", \" kick\", \" off\", \" the\", \" 2009\", \" Great\", \" Rom\", \"antics\", \" national\", \" tour\", \"\\n\", \"\\n\", \"S\", \"yd\", \"ney\", \",\", \" 11\", \" June\", \" 2009\", \":\", \" The\", \" Commonwealth\", \" Bank\", \" today\", \" congrat\", \"ulated\", \" the\", \" Australian\", \" Chamber\", \" Orchestra\", \" (\", \"AC\", \"O\", \")\", \" on\", \" the\", \" commencement\", \" of\", \" its\", \" Great\", \" Rom\", \"antics\", \" Tour\", \".\", \"\\n\", \"\\n\", \"Common\", \"wealth\", \" Bank\", \" Group\", \" Executive\", \" Human\", \" Resources\", \" and\", \" Group\", \" Services\", \",\", \" Ms\", \" Barbara\", \" Chapman\", \",\", \" said\", \" the\", \" Group\", \" was\", \" committed\", \" to\", \" supporting\", \" the\", \" Arts\", \" in\", \" Australia\", \" and\", \" helping\", \" its\", \" customers\"], [\"Ben\", \"jamin\", \" Lok\", \" describes\", \" how\", \" the\", \" robot\", \" butt\", \" sensors\", \" work\", \" 2\", \":\", \"26\", \"\\n\", \"\\n\", \"Pro\", \"state\", \" exams\", \" are\", \" potentially\", \"-\", \"life\", \" saving\", \".\", \" But\", \" the\", \" process\", \" of\", \" getting\", \" one\", \" can\", \" be\", \" nerve\", \"-\", \"r\", \"acking\", \" \\u2014\", \" both\", \" for\", \" the\", \" doctor\", \" and\", \" the\", \" patient\", \".\", \"\\n\", \"\\n\", \"A\", \" group\", \" of\", \" scientists\", \" from\", \" D\", \"rex\", \"el\", \" University\", \" and\", \" the\", \" Univers\", \"ities\", \" of\", \" Wisconsin\", \" and\", \" Florida\", \" are\", \" hoping\", \" to\", \" assist\", \" with\", \" that\", \".\", \" They\", \"'ve\", \" designed\", \" a\", \" robot\", \" to\", \" help\", \" medical\", \" students\", \" give\", \" better\", \" prostate\", \" exams\", \".\", \"\\n\", \"\\n\", \"The\", \" robot\", \"'s\", \" name\", \" is\", \" \\\"\", \"Patrick\", \"\\\"\", \" and\", \" he\", \"'s\", \" an\", \" interactive\", \" butt\", \".\", \"\\n\", \"\\n\", \"Professor\", \" Benjamin\", \" Lok\", \"\\n\", \"\\n\", \"\\\"\", \"Patrick\", \" is\", \" part\", \" of\", \" a\", \" simulation\", \" where\", \" students\"], [\"New\", \" York\", \" (\", \"CNN\", \" Business\", \")\", \" On\", \" Sunday\", \",\", \" Ford\", \" will\", \" announce\", \" what\", \" is\", \" possibly\", \" the\", \" biggest\", \" change\", \" ever\", \" in\", \" the\", \" 55\", \"-\", \"year\", \" history\", \" of\", \" the\", \" Must\", \"ang\", \".\", \"\\n\", \"\\n\", \"The\", \" autom\", \"aker\", \" will\", \" unve\", \"il\", \" a\", \" vehicle\", \" bearing\", \" the\", \" Must\", \"ang\", \" brand\", \" that\", \"'s\", \" not\", \" a\", \" two\", \"-\", \"door\", \" car\", \".\", \"\\n\", \"\\n\", \"Call\", \"ed\", \" the\", \" Ford\", \" Must\", \"ang\", \" Mach\", \"-\", \"E\", \",\", \" it\", \"'s\", \" a\", \" fully\", \" electric\", \" crossover\", \" SUV\", \" that\", \" will\", \" wear\", \" the\", \" Must\", \"ang\", \"'s\", \" chrome\", \" pony\", \".\", \"\\n\", \"\\n\", \"F\", \"ord\", \" has\", \" apparently\", \" learned\", \" from\", \" brands\", \" like\", \" P\", \"orsche\", \",\", \" Lamb\", \"org\", \"h\", \"ini\", \" and\", \" Je\", \"ep\", \" that\", \" even\", \" ar\", \"dent\", \" fans\"], [\"It\", \" is\", \" a\", \" tr\", \"u\", \"ism\", \" that\", \" modern\", \" cell\", \" phones\", \" feature\", \" a\", \" multitude\", \" of\", \" features\", \" that\", \" expand\", \" on\", \" the\", \" traditional\", \" cell\", \" phone\", \" functionality\", \".\", \" For\", \" example\", \",\", \" today\", \" cell\", \" phone\", \" users\"]], \"activations\": [[[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.21400916576385498]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.2162028551101685]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.16583633422851562]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.01831185817718506]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.5287742614746094]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.24253559112548828]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.10928785800933838]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.253542900085449]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.21400916576385498]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.2162028551101685]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.16583633422851562]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.01831185817718506]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.5287742614746094]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.2006239891052246]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7577693462371826]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.1463074684143066]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.011271357536315918]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.1062750816345215]]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdde81ac7f0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens, activations = topk_prompts_provider(\n",
    "    feature_layer=3,\n",
    "    feature_id=26928,\n",
    "    k=5\n",
    ")\n",
    "text_neuron_activations(tokens, activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check wheter different patching methods agree in which upstream features have the highest effect on the downstream feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all-folded</th>\n",
       "      <th>separate</th>\n",
       "      <th>ig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layer0_top1</th>\n",
       "      <td>15149</td>\n",
       "      <td>15149</td>\n",
       "      <td>21840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer0_top2</th>\n",
       "      <td>21848</td>\n",
       "      <td>21848</td>\n",
       "      <td>21855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer0_top3</th>\n",
       "      <td>21841</td>\n",
       "      <td>21841</td>\n",
       "      <td>21854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_top1</th>\n",
       "      <td>14400</td>\n",
       "      <td>14400</td>\n",
       "      <td>14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_top2</th>\n",
       "      <td>1566</td>\n",
       "      <td>25045</td>\n",
       "      <td>25045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_top3</th>\n",
       "      <td>14721</td>\n",
       "      <td>10964</td>\n",
       "      <td>10964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer2_top1</th>\n",
       "      <td>27186</td>\n",
       "      <td>12654</td>\n",
       "      <td>12654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer2_top2</th>\n",
       "      <td>12654</td>\n",
       "      <td>27186</td>\n",
       "      <td>27186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer2_top3</th>\n",
       "      <td>31615</td>\n",
       "      <td>13579</td>\n",
       "      <td>13579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer3_top1</th>\n",
       "      <td>26928</td>\n",
       "      <td>26928</td>\n",
       "      <td>26928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer3_top2</th>\n",
       "      <td>20945</td>\n",
       "      <td>20945</td>\n",
       "      <td>20945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer3_top3</th>\n",
       "      <td>17355</td>\n",
       "      <td>17355</td>\n",
       "      <td>17355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer4_top1</th>\n",
       "      <td>2871</td>\n",
       "      <td>2871</td>\n",
       "      <td>2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer4_top2</th>\n",
       "      <td>11028</td>\n",
       "      <td>11028</td>\n",
       "      <td>11028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer4_top3</th>\n",
       "      <td>9616</td>\n",
       "      <td>9616</td>\n",
       "      <td>9616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             all-folded  separate     ig\n",
       "layer0_top1       15149     15149  21840\n",
       "layer0_top2       21848     21848  21855\n",
       "layer0_top3       21841     21841  21854\n",
       "layer1_top1       14400     14400  14400\n",
       "layer1_top2        1566     25045  25045\n",
       "layer1_top3       14721     10964  10964\n",
       "layer2_top1       27186     12654  12654\n",
       "layer2_top2       12654     27186  27186\n",
       "layer2_top3       31615     13579  13579\n",
       "layer3_top1       26928     26928  26928\n",
       "layer3_top2       20945     20945  20945\n",
       "layer3_top3       17355     17355  17355\n",
       "layer4_top1        2871      2871   2871\n",
       "layer4_top2       11028     11028  11028\n",
       "layer4_top3        9616      9616   9616"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = ['all-folded', 'separate', 'ig'] #, 'exact']\n",
    "topk_upstream_feats_across_methods = pd.DataFrame()\n",
    "df_idx = [f'layer{layer}_top{i+1}' for layer in range(downstream_feat_layer) for i in range(k_upstream_feats)]\n",
    "for method in methods:\n",
    "    topk_upstream_feats = t.zeros((downstream_feat_layer, k_upstream_feats), dtype=int)\n",
    "\n",
    "    effects_on_dsfeat, total_effect_on_dsfeat = patching_on_downstream_feature(\n",
    "        toy_dataset,\n",
    "        model,\n",
    "        upstream_submodules=submodules[:downstream_feat_layer],\n",
    "        upstream_dictionaries=dictionaries[:downstream_feat_layer],\n",
    "        downstream_submodule=submodules[downstream_feat_layer],\n",
    "        downstream_dictionary=dictionaries[downstream_feat_layer],\n",
    "        downstream_feature_id=downstream_feat_id,\n",
    "        method=method,\n",
    "    )\n",
    "    for layer in range(downstream_feat_layer):\n",
    "        effects_on_dsfeat_per_layer = effects_on_dsfeat[submodules[layer]][plural_token_pos].detach().cpu() # Only effect on token position `plural_token_pos` matters for \"Plurals\" task\n",
    "        topk_upstream_feats[layer] = t.argsort(effects_on_dsfeat_per_layer, descending=True)[:k_upstream_feats]\n",
    "\n",
    "    topk_upstream_feats_across_methods[method] = topk_upstream_feats.flatten()\n",
    "\n",
    "topk_upstream_feats_across_methods.index = df_idx\n",
    "topk_upstream_feats_across_methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
