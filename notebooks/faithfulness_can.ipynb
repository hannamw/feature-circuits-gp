{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "from activation_utils import SparseAct\n",
    "import torch as t\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from loading_utils import load_examples\n",
    "from dictionary_learning import AutoEncoder\n",
    "from dictionary_learning.dictionary import IdentityDict\n",
    "from ablation_sam import run_with_ablations\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map=device, dispatch=True)\n",
    "\n",
    "start_layer = 0 # explain the model starting here\n",
    "\n",
    "feature_circuit = t.load('circuits/rc_dict10_node0.1_edge0.01_n30_aggsum.pt')['nodes']\n",
    "neuron_circuit = t.load('circuits/rc_dictid_node0.02_edge0.002_n30_aggsum.pt')['nodes']\n",
    "\n",
    "examples = load_examples('/share/projects/dictionary_circuits/data/phenomena/rc_test.json', 40, model, length=6)\n",
    "\n",
    "ablation = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load submodules\n",
    "submodules = []\n",
    "if start_layer < 0: submodules.append(model.gpt_neox.embed_in)\n",
    "for i in range(start_layer, len(model.gpt_neox.layers)):\n",
    "    submodules.extend([\n",
    "        model.gpt_neox.layers[i].attention,\n",
    "        model.gpt_neox.layers[i].mlp,\n",
    "        model.gpt_neox.layers[i]\n",
    "    ])\n",
    "\n",
    "submod_names = {\n",
    "    model.gpt_neox.embed_in : 'embed'\n",
    "}\n",
    "for i in range(len(model.gpt_neox.layers)):\n",
    "    submod_names[model.gpt_neox.layers[i].attention] = f'attn_{i}'\n",
    "    submod_names[model.gpt_neox.layers[i].mlp] = f'mlp_{i}'\n",
    "    submod_names[model.gpt_neox.layers[i]] = f'resid_{i}'\n",
    "\n",
    "\n",
    "# select submodules\n",
    "criterium = \"mlp\"\n",
    "criterium_name = \"feature_\" + criterium\n",
    "selected_sumodules = []\n",
    "for submod in submodules:\n",
    "    name = submod_names[submod]\n",
    "    if criterium in name:\n",
    "        selected_sumodules.append(submod)\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionaries\n",
    "dict_id = 10\n",
    "\n",
    "activation_dim = 512\n",
    "expansion_factor = 64\n",
    "dict_size = expansion_factor * activation_dim\n",
    "\n",
    "feat_dicts = {}\n",
    "ae = AutoEncoder(activation_dim, dict_size).to(device)\n",
    "ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/embed/{dict_id}_{dict_size}/ae.pt'))\n",
    "feat_dicts[model.gpt_neox.embed_in] = ae\n",
    "for i in range(len(model.gpt_neox.layers)):\n",
    "    ae = AutoEncoder(activation_dim, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/attn_out_layer{i}/{dict_id}_{dict_size}/ae.pt'))\n",
    "    feat_dicts[model.gpt_neox.layers[i].attention] = ae\n",
    "\n",
    "    ae = AutoEncoder(activation_dim, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/mlp_out_layer{i}/{dict_id}_{dict_size}/ae.pt'))\n",
    "    feat_dicts[model.gpt_neox.layers[i].mlp] = ae\n",
    "\n",
    "    ae = AutoEncoder(activation_dim, dict_size).to(device)\n",
    "    ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/resid_out_layer{i}/{dict_id}_{dict_size}/ae.pt'))\n",
    "    feat_dicts[model.gpt_neox.layers[i]] = ae\n",
    "\n",
    "neuron_dicts = {\n",
    "    submod : IdentityDict(activation_dim).to(device) for submod in submodules\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "clean_inputs = t.cat([e['clean_prefix'] for e in examples], dim=0).to('cuda:0')\n",
    "clean_answer_idxs = t.tensor([e['clean_answer'] for e in examples], dtype=t.long, device='cuda:0')\n",
    "patch_inputs = t.cat([e['patch_prefix'] for e in examples], dim=0).to('cuda:0')\n",
    "patch_answer_idxs = t.tensor([e['patch_answer'] for e in examples], dtype=t.long, device='cuda:0')\n",
    "\n",
    "\n",
    "def metric_fn(model):\n",
    "    return (\n",
    "        - t.gather(model.embed_out.output[:,-1,:], dim=-1, index=patch_answer_idxs.view(-1, 1)).squeeze(-1) + \\\n",
    "        t.gather(model.embed_out.output[:,-1,:], dim=-1, index=clean_answer_idxs.view(-1, 1)).squeeze(-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ablation fn\n",
    "# if args.ablation == 'resample': ablation_fn = lambda x: x[t.randperm(x.act.shape[0])] # TODO this is wrong for SparseActs\n",
    "if ablation == 'zero': ablation_fn = lambda x: x.zeros_like()\n",
    "if ablation == 'mean': ablation_fn = lambda x: x.mean(dim=0).expand_as(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get F(M)\n",
    "with model.trace(clean_inputs), t.no_grad():\n",
    "    metric = metric_fn(model).save()\n",
    "fm = metric.value.mean()\n",
    "print(f\"F(M) = {fm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get F(∅)\n",
    "# fempty = run_with_ablations(\n",
    "#     clean_inputs,\n",
    "#     patch_inputs,\n",
    "#     model,\n",
    "#     submodules,\n",
    "#     feat_dicts,\n",
    "#     nodes = {\n",
    "#         submod : SparseAct(act=t.zeros(dict_size, dtype=t.bool), resc=t.zeros(1, dtype=t.bool)).to(device)\n",
    "#         for submod in submodules\n",
    "#     },\n",
    "#     metric_fn=metric_fn,\n",
    "#     ablation_fn=ablation_fn\n",
    "# )\n",
    "# fempty = fempty.mean()\n",
    "# print(f\"F(∅) = {fempty}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweeping over thresholds, get fc and fc' for:\n",
    "# feature circuit with residuals\n",
    "# feature circuit without residuals\n",
    "# neuron circuit\n",
    "# random feature circuit with all residuals\n",
    "\n",
    "fc = {'features' : {}, 'features_wo_resids' : {}, 'neurons' : {}, 'random' : {}}\n",
    "fccomp = {'features' : {}, 'features_wo_resids' : {}, 'neurons' : {}, 'random' : {}}\n",
    "n_nodes = {'features' : {}, 'features_wo_resids' : {}, 'neurons' : {}, 'random' : {}}\n",
    "fempties = dict()\n",
    "\n",
    "thresholds = t.logspace(-4, -1, 20, 10)\n",
    "layers = range(start_layer, len(model.gpt_neox.layers))\n",
    "with t.no_grad():\n",
    "    for layer in layers:\n",
    "        for keys in fc.keys():\n",
    "            fc[keys][layer] = dict()\n",
    "            fccomp[keys][layer] = dict()\n",
    "            n_nodes[keys][layer] = dict()\n",
    "\n",
    "        # select submodules\n",
    "        criterium = str(layer)\n",
    "        criterium_name = f'layer_{criterium}'\n",
    "        selected_submodules = []\n",
    "        names = []\n",
    "        for submod in submodules:\n",
    "            name = submod_names[submod]\n",
    "            if criterium in name and not 'resid' in name:\n",
    "                selected_submodules.append(submod)\n",
    "                names.append(name)\n",
    "        print(f'Layer {layer}: {names} submodules')\n",
    "\n",
    "        # get F(∅)\n",
    "        fempties[layer] = run_with_ablations(\n",
    "            clean_inputs,\n",
    "            patch_inputs,\n",
    "            model,\n",
    "            selected_submodules,\n",
    "            feat_dicts,\n",
    "            nodes = {\n",
    "                submod : SparseAct(act=t.zeros(dict_size, dtype=t.bool), resc=t.zeros(1, dtype=t.bool)).to(device)\n",
    "                for submod in selected_submodules\n",
    "            },\n",
    "            metric_fn=metric_fn,\n",
    "            ablation_fn=ablation_fn\n",
    "        ).mean()\n",
    "\n",
    "        for threshold in tqdm(thresholds):        \n",
    "            feat_nodes = {\n",
    "                submod : feature_circuit[submod_names[submod]].abs() > threshold for submod in selected_submodules\n",
    "            }\n",
    "            neuron_nodes = {\n",
    "                submod : neuron_circuit[submod_names[submod]].abs() > threshold for submod in selected_submodules\n",
    "            }\n",
    "            n_nodes['features'][layer][threshold] = sum([feat_nodes[submod].act.sum().item() + feat_nodes[submod].resc.sum().item() for submod in selected_submodules])\n",
    "            n_nodes['features_wo_resids'][layer][threshold] = sum([feat_nodes[submod].act.sum().item() for submod in selected_submodules])\n",
    "            n_nodes['neurons'][layer][threshold] = sum([neuron_nodes[submod].act.sum().item() for submod in selected_submodules])\n",
    "            n_nodes['random'][layer][threshold] = n_nodes['features_wo_resids'][layer][threshold]\n",
    "\n",
    "            random_nodes = {}\n",
    "            for submod in selected_submodules:\n",
    "                nodes = SparseAct(act=t.zeros(dict_size, dtype=t.bool), resc=t.ones(1, dtype=t.bool)).to(device)\n",
    "                nodes.act[t.randperm(dict_size)[:n_nodes['random'][layer][threshold]]] = True\n",
    "                random_nodes[submod] = nodes\n",
    "\n",
    "            fc['features'][layer][threshold] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                selected_submodules,\n",
    "                feat_dicts,\n",
    "                nodes=feat_nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn\n",
    "            ).mean()\n",
    "            fc['features_wo_resids'][layer][threshold] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                selected_submodules,\n",
    "                feat_dicts,\n",
    "                nodes=feat_nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "                handle_resids='remove'\n",
    "            ).mean()\n",
    "            fc['neurons'][layer][threshold] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                selected_submodules,\n",
    "                neuron_dicts,\n",
    "                nodes=neuron_nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn\n",
    "            ).mean()\n",
    "            fc['random'][layer][threshold] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                selected_submodules,\n",
    "                feat_dicts,\n",
    "                nodes=random_nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn\n",
    "            ).mean()\n",
    "            fccomp['features'][layer][threshold] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                selected_submodules,\n",
    "                feat_dicts,\n",
    "                nodes=feat_nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "                complement=True\n",
    "            ).mean()\n",
    "            fccomp['features_wo_resids'][layer][threshold] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                selected_submodules,\n",
    "                feat_dicts,\n",
    "                nodes=feat_nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "                handle_resids='keep',\n",
    "                complement=True\n",
    "            ).mean()\n",
    "            fccomp['neurons'][layer][threshold] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                selected_submodules,\n",
    "                neuron_dicts,\n",
    "                nodes=neuron_nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "                complement=True\n",
    "            ).mean()\n",
    "            fccomp['random'][layer][threshold] = run_with_ablations(\n",
    "                clean_inputs,\n",
    "                patch_inputs,\n",
    "                model,\n",
    "                selected_submodules,\n",
    "                feat_dicts,\n",
    "                nodes=random_nodes,\n",
    "                metric_fn=metric_fn,\n",
    "                ablation_fn=ablation_fn,\n",
    "                complement=True\n",
    "            ).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faithfulness(fc, fempty, fm):\n",
    "    return ((fc - fempty) / (fm - fempty)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fempties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "# Define the range of layers\n",
    "layer_range = list(range(start_layer, len(model.gpt_neox.layers)))\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "# Add a scatter trace for the current layer\n",
    "# Create a scatter plot for each layer\n",
    "colors = dict(features='blue', features_wo_resids='turquoise', neurons='red', random='black')\n",
    "\n",
    "for fc_name in fc.keys():        \n",
    "        for layer in layer_range:\n",
    "                num_nodes = list(n_nodes[fc_name][layer].values())\n",
    "                x_title = \"Number of nodes\"\n",
    "                x_range = [0, 3.5]\n",
    "                ys = [faithfulness(x, fempties[layer], fm) for x in fc[fc_name][layer].values()]\n",
    "\n",
    "                if layer == layer_range[0]:\n",
    "                        visible = True\n",
    "                else:\n",
    "                        visible = False\n",
    "                \n",
    "                # Add a scatter trace for the current layer\n",
    "                fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                                x=num_nodes, \n",
    "                                y=ys, \n",
    "                                mode=\"markers\", \n",
    "                                name=f\"{fc_name} layer {layer} (#nodes)\",\n",
    "                                text=[f\"Threshold: {t:.2e}<br>Nodes: {n}<br>Faithfulness: {f:.2f}\" for t, n, f in zip(thresholds, num_nodes, ys)],\n",
    "                                hoverinfo=\"text\",\n",
    "                                marker=dict(color=colors[fc_name]),\n",
    "                                visible=visible\n",
    "                        ),\n",
    "                        row=1,\n",
    "                        col=1\n",
    "                )\n",
    "                x_title = \"Node_threshold\"\n",
    "                x_range = None\n",
    "                \n",
    "                # Add a scatter trace for the current layer\n",
    "                fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                                x=thresholds, \n",
    "                                y=ys, \n",
    "                                mode=\"markers\", \n",
    "                                name=f\"{fc_name} layer {layer} (thresh)\",\n",
    "                                text=[f\"Threshold: {t:.2e}<br>Nodes: {n}<br>Faithfulness: {f:.2f}\" for t, n, f in zip(thresholds, num_nodes, ys)],\n",
    "                                hoverinfo=\"text\",\n",
    "                                marker=dict(color=colors[fc_name]),\n",
    "                                visible=visible\n",
    "                        ),\n",
    "                        row=1,\n",
    "                        col=2\n",
    "                )\n",
    "\n",
    "# Instead of a single update_layout call, use update_xaxes and update_yaxes\n",
    "fig.update_layout(\n",
    "    title=\"Faithfulness of single layers of C\",\n",
    "    yaxis=dict(title=\"Faithfulness\"),\n",
    "    # Additional overall layout configurations here...\n",
    ")\n",
    "\n",
    "# Update x-axis for column 1\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Number of nodes\",  # First plot x-axis title\n",
    "    type=\"log\", \n",
    "    range=[0, 3.5],  # Set your desired range\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Update x-axis for column 2\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Node threshold\",  # Second plot x-axis title\n",
    "    type=\"log\",\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Slider updates (keep this if applicable to your figure)\n",
    "fig.update_layout(\n",
    "    sliders=[\n",
    "        dict(\n",
    "            active=0,\n",
    "            pad={\"t\": 50},\n",
    "            steps=[\n",
    "                dict(\n",
    "                    label=f\"Layer {layer}\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [layer == i for i in sorted(layer_range+layer_range)]}],\n",
    "                ) for layer in layer_range\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "# Show the figure\n",
    "fig.write_html(\"faithfulness_per_layer.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio.tools as tls\n",
    "\n",
    "# Replace 'your_username' and 'your_api_key' with your actual Plotly username and API key\n",
    "chart_studio.tools.set_credentials_file(username='canrager', api_key='uOXzoIv31B8E76vv7mu3')\n",
    "\n",
    "py.plot(fig, filename=\"Faithfulness of single layers of C\", auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.where(t.tensor(list(fc['features'][0].values())) > 0.9)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness_threshs = t.linspace(0.9, 1, 10)\n",
    "max_thresholds_dict = defaultdict(list)\n",
    "fc_names = [\"neurons\", \"features\"]\n",
    "for faithfulness_thresh in faithfulness_threshs:\n",
    "    for fc_name in fc_names:\n",
    "        for layer in layer_range:\n",
    "            faithfulness_per_layer = [faithfulness(fc, fempties[layer], fm) for fc in fc[fc_name][layer].values()]\n",
    "            faithfulness_per_layer = t.tensor(faithfulness_per_layer)\n",
    "            largest_thresh = thresholds[t.where(faithfulness_per_layer > faithfulness_thresh)[0]]\n",
    "            if len(largest_thresh) > 0:\n",
    "                max_thresholds_dict[faithfulness_thresh.item()].append((layer, fc_name, largest_thresh[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the thresholds over the layers\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "# Create a scatter plot for each layer\n",
    "for faithfulness_thresh, max_thresholds in max_thresholds_dict.items():\n",
    "        fc_name = \"features\"\n",
    "        xs = list(layers)\n",
    "        ys = [threshold for l, f, threshold in max_thresholds if f == fc_name]\n",
    "        # Add a scatter trace for the current layer\n",
    "        fig.add_trace(\n",
    "                go.Scatter(\n",
    "                        x=xs, \n",
    "                        y=ys, \n",
    "                        mode=\"markers\", \n",
    "                        name=f\"{faithfulness_thresh:.2f}\",\n",
    "                        # marker=dict(color=colors[fc_name])\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1\n",
    "        )\n",
    "\n",
    "# Set the layout of the figure\n",
    "        \n",
    "fig.update_layout(\n",
    "        title=f\"Max threshold  to achieve at least a specific faithfulness score\",\n",
    "        xaxis=dict(title=\"Layer\"),\n",
    "        yaxis=dict(title=\"Threshold for removing features from a ciruit\", type=\"log\"),\n",
    "        legend=dict(title=\"Faithfulness threshold\"),\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.write_html(\"thresholds_per_layer.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submodules[0].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model.trace(clean_inputs), t.no_grad():\n",
    "    submodule_input = submodules[0].input.save()\n",
    "\n",
    "submodule_input.value[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sender_nodes doct mapping sender: output\n",
    "# receiver: dict mapping receiver to senders\n",
    "\n",
    "# tracing call\n",
    "\n",
    "# sender_outputs = defaultdict(list)\n",
    "# for all nodes in circuit\n",
    "\n",
    "\n",
    "## Structure\n",
    "# get outputs of submodules on patch inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
