{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/u/smarks/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(nn.Module):\n",
    "    def __init__(self, activation_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(activation_dim, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x).squeeze(-1)\n",
    "        return logits.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 20\n",
    "layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control probe 1 accuracy: 0.970802903175354\n",
      "Control probe 2 accuracy: 0.9927006959915161\n"
     ]
    }
   ],
   "source": [
    "t.manual_seed(42)\n",
    "\n",
    "# train control probes for each feature individually\n",
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "feat1_labels = t.randint(0, 2, (len(train_data),)).to(device)\n",
    "feat2_labels = t.randint(0, 2, (len(train_data),)).to(device)\n",
    "inputs = []\n",
    "for (_, row), label1, label2 in zip(train_data.iterrows(), feat1_labels, feat2_labels):\n",
    "    if label1 == 0 and label2 == 0:\n",
    "        inputs.append(row['singular'])\n",
    "    elif label1 == 0 and label2 == 1:\n",
    "        inputs.append(row['singular'].upper())\n",
    "    elif label1 == 1 and label2 == 0:\n",
    "        inputs.append(row['plural'])\n",
    "    elif label1 == 1 and label2 == 1:\n",
    "        inputs.append(row['plural'].upper())\n",
    "\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "probe1 = Probe(acts.shape[-1]).to(device)\n",
    "probe2 = Probe(acts.shape[-1]).to(device)\n",
    "opt1 = t.optim.AdamW(probe1.parameters(), lr=lr)\n",
    "opt2 = t.optim.AdamW(probe2.parameters(), lr=lr)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    opt1.zero_grad(), opt2.zero_grad()\n",
    "    logits1 = probe1(acts)\n",
    "    logits2 = probe2(acts)\n",
    "    loss1 = nn.BCELoss()(logits1, feat1_labels.float())\n",
    "    loss2 = nn.BCELoss()(logits2, feat2_labels.float())\n",
    "    loss1.backward(), loss2.backward()\n",
    "    opt1.step(), opt2.step()\n",
    "\n",
    "# test control probes\n",
    "test_data = pd.read_csv('data/test_data.csv')\n",
    "feat1_labels = t.randint(0, 2, (len(test_data),)).to(device)\n",
    "feat2_labels = t.randint(0, 2, (len(test_data),)).to(device)\n",
    "inputs = []\n",
    "for (_, row), label1, label2 in zip(test_data.iterrows(), feat1_labels, feat2_labels):\n",
    "    if label1 == 0 and label2 == 0:\n",
    "        inputs.append(row['singular'])\n",
    "    elif label1 == 0 and label2 == 1:\n",
    "        inputs.append(row['singular'].upper())\n",
    "    elif label1 == 1 and label2 == 0:\n",
    "        inputs.append(row['plural'])\n",
    "    elif label1 == 1 and label2 == 1:\n",
    "        inputs.append(row['plural'].upper())\n",
    "\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "probs1 = probe1(acts)\n",
    "probs2 = probe2(acts)\n",
    "preds1, preds2 = probs1.round(), probs2.round()\n",
    "acc1 = (preds1 == feat1_labels).float().mean().item()\n",
    "acc2 = (preds2 == feat2_labels).float().mean().item()\n",
    "\n",
    "print(f'Control probe 1 accuracy: {acc1}')\n",
    "print(f'Control probe 2 accuracy: {acc2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(42)\n",
    "probe = Probe(512).to(device)\n",
    "optimizer = t.optim.AdamW(probe.parameters(), lr=lr)\n",
    "losses = []\n",
    "\n",
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "labels = t.randint(0, 2, (len(train_data),)).to(device)\n",
    "inputs = [\n",
    "    row['singular'] if label == 0 else row['plural'].upper() for (_, row), label in zip(train_data.iterrows(), labels)\n",
    "]\n",
    "train_inputs = inputs\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "for _ in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    probs = probe(acts)\n",
    "    loss = nn.BCELoss()(probs, labels.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0341346263885498,\n",
       " 0.5637803673744202,\n",
       " 0.5266983509063721,\n",
       " 0.44276073575019836,\n",
       " 0.3562548756599426,\n",
       " 0.2869155704975128,\n",
       " 0.23607821762561798,\n",
       " 0.20007425546646118,\n",
       " 0.1744411736726761,\n",
       " 0.1548157036304474,\n",
       " 0.13781310617923737,\n",
       " 0.12156275659799576,\n",
       " 0.10560642927885056,\n",
       " 0.09034047275781631,\n",
       " 0.07642094045877457,\n",
       " 0.064373679459095,\n",
       " 0.05443716421723366,\n",
       " 0.04657389223575592,\n",
       " 0.04056061804294586,\n",
       " 0.036086101084947586]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc on ambiguous: 1.0\n",
      "feat1_acc: 0.5766423344612122, feat2_acc: 0.970802903175354\n"
     ]
    }
   ],
   "source": [
    "t.manual_seed(42)\n",
    "# get accuracy on ambiguous test set\n",
    "test_data = pd.read_csv('data/test_data.csv')\n",
    "labels = t.randint(0, 2, (len(test_data),)).to(device)\n",
    "inputs = [\n",
    "    row['singular'] if label == 0 else row['plural'].upper() for (_, row), label in zip(test_data.iterrows(), labels)\n",
    "]\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "preds = probe(acts).round().long()\n",
    "acc = (preds == labels).float().mean().item()\n",
    "print(f'acc on ambiguous: {acc}')\n",
    "\n",
    "t.manual_seed(42)\n",
    "# get accuracy on disambiguating test set\n",
    "test_data = pd.read_csv('data/test_data.csv')\n",
    "feat1_labels = t.randint(0, 2, (len(test_data),)).to(device)\n",
    "feat2_labels = t.randint(0, 2, (len(test_data),)).to(device)\n",
    "inputs = []\n",
    "for (_, row), label1, label2 in zip(test_data.iterrows(), feat1_labels, feat2_labels):\n",
    "    if label1 == 0 and label2 == 0:\n",
    "        inputs.append(row['singular'])\n",
    "    elif label1 == 0 and label2 == 1:\n",
    "        inputs.append(row['singular'].upper())\n",
    "    elif label1 == 1 and label2 == 0:\n",
    "        inputs.append(row['plural'])\n",
    "    elif label1 == 1 and label2 == 1:\n",
    "        inputs.append(row['plural'].upper())\n",
    "test_inputs = inputs\n",
    "\n",
    "with model.invoke(inputs):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "preds = probe(acts).round().long()\n",
    "feat1_acc = (preds == feat1_labels).float().mean().item()\n",
    "feat2_acc = (preds == feat2_labels).float().mean().item()\n",
    "print(f'feat1_acc: {feat1_acc}, feat2_acc: {feat2_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "    Multindex: (4324,), Value: 0.028520982712507248\n",
      "    Multindex: (4362,), Value: 0.011580727994441986\n",
      "    Multindex: (5650,), Value: 0.03548774868249893\n",
      "    Multindex: (8537,), Value: 0.011580727994441986\n",
      "    Multindex: (17126,), Value: 0.012919182889163494\n",
      "    Multindex: (22182,), Value: 0.013656112365424633\n",
      "    Multindex: (25864,), Value: 0.05403883755207062\n",
      "    Multindex: (29293,), Value: 0.018411755561828613\n",
      "    Multindex: (32286,), Value: 0.011580727994441986\n",
      "Layer 1:\n",
      "    Multindex: (740,), Value: 0.01760883629322052\n",
      "    Multindex: (14465,), Value: 0.06407757103443146\n",
      "    Multindex: (16629,), Value: 0.011317379772663116\n",
      "    Multindex: (17573,), Value: 0.01387042086571455\n",
      "    Multindex: (18471,), Value: 0.13989761471748352\n",
      "    Multindex: (19812,), Value: 0.01919487677514553\n",
      "    Multindex: (22990,), Value: 0.020656585693359375\n",
      "    Multindex: (27592,), Value: 0.021570025011897087\n",
      "    Multindex: (27759,), Value: 0.017101265490055084\n",
      "    Multindex: (27933,), Value: 0.01761571504175663\n",
      "    Multindex: (32669,), Value: 0.018336789682507515\n",
      "Layer 2:\n",
      "    Multindex: (16421,), Value: 0.029878858476877213\n",
      "    Multindex: (17187,), Value: 0.022526796907186508\n",
      "    Multindex: (22968,), Value: 0.058273594826459885\n",
      "    Multindex: (27888,), Value: 0.054936863481998444\n",
      "    Multindex: (30868,), Value: 0.022143755108118057\n"
     ]
    }
   ],
   "source": [
    "from attribution import patching_effect\n",
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "\n",
    "submodules = [\n",
    "    model.gpt_neox.layers[i] for i in range(layer + 1)\n",
    "]\n",
    "dictionaries = []\n",
    "for i in range(layer + 1):\n",
    "    ae = AutoEncoder(512, 64 * 512).to(device)\n",
    "    ae.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/resid_out_layer{i}/0_32768/ae.pt'))\n",
    "    dictionaries.append(ae)\n",
    "\n",
    "def metric_fn(model):\n",
    "    return probe(model.gpt_neox.layers[layer].output[0][:,-1,:])\n",
    "\n",
    "effects, _ = patching_effect(\n",
    "    \"YARNS\",\n",
    "    None,\n",
    "    model,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    metric_fn,\n",
    "    method='ig'\n",
    ")\n",
    "\n",
    "effects = {k : v.abs().mean(dim=0).mean(dim=0) for k, v in effects.items()}\n",
    "for i, submodule in enumerate(submodules):\n",
    "    print(f\"Layer {i}:\")\n",
    "    effect = effects[submodule]\n",
    "    for feature_idx in t.nonzero(effect):\n",
    "        value = effect[tuple(feature_idx)]\n",
    "        if value.abs() > 0.01:\n",
    "            print(f\"    Multindex: {tuple(feature_idx.tolist())}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 0.8413950800895691, after: 0.37445271015167236\n"
     ]
    }
   ],
   "source": [
    "input = \"YARNS\"\n",
    "\n",
    "to_ablate = {\n",
    "    submodules[0] : [\n",
    "        5650,\n",
    "        17126,\n",
    "        22182,\n",
    "        25864\n",
    "    ],\n",
    "    submodules[1] : [\n",
    "        14465,\n",
    "        18471,\n",
    "        22990\n",
    "    ],\n",
    "    submodules[2] : [\n",
    "        16421,\n",
    "        22968,\n",
    "        27888\n",
    "    ]\n",
    "}\n",
    "\n",
    "with model.invoke(input):\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "pred_before = probe(acts).item()\n",
    "\n",
    "with model.invoke(input):\n",
    "    for submodule, dictionary in zip(submodules, dictionaries):\n",
    "        x = submodule.output\n",
    "        is_resid = type(x.shape) == tuple\n",
    "        if is_resid:\n",
    "            x = x[0]\n",
    "        x_hat = dictionary(x)\n",
    "        residual = x - x_hat\n",
    "        \n",
    "        f = dictionary.encode(x)\n",
    "        ablation_idxs = to_ablate[submodule]\n",
    "        for idx in ablation_idxs:\n",
    "            f[..., idx] = 0\n",
    "        x_hat = dictionary.decode(f)\n",
    "        if is_resid:\n",
    "            submodule.output[0][:] = x_hat + residual\n",
    "        else:\n",
    "            submodule.output = x_hat + residual\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "pred_after = probe(acts).item()\n",
    "\n",
    "print(f'before: {pred_before}, after: {pred_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc on ambiguous: 1.0\n",
      "feat1_acc: 0.5912408828735352, feat2_acc: 0.8978102207183838\n"
     ]
    }
   ],
   "source": [
    "# get mean feature activations on train set\n",
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "labels = t.randint(0, 2, (len(train_data),)).to(device)\n",
    "inputs = [\n",
    "    row['singular'] if label == 0 else row['plural'].upper() for (_, row), label in zip(train_data.iterrows(), labels)\n",
    "]\n",
    "\n",
    "ablation_values = {}\n",
    "with model.invoke(inputs):\n",
    "    for submodule, dictionary in zip(submodules, dictionaries):\n",
    "        x = submodule.output\n",
    "        is_resid = type(x.shape) == tuple\n",
    "        if is_resid:\n",
    "            x = x[0]\n",
    "        f = dictionary.encode(x)\n",
    "        ablation_values[submodule] = f[:, -1, t.Tensor(to_ablate[submodule]).long()].mean(dim=0)\n",
    "\n",
    "t.manual_seed(42)\n",
    "# get accuracy on ambiguous test set\n",
    "test_data = pd.read_csv('data/test_data.csv')\n",
    "labels = t.randint(0, 2, (len(test_data),)).to(device)\n",
    "inputs = [\n",
    "    row['singular'] if label == 0 else row['plural'].upper() for (_, row), label in zip(test_data.iterrows(), labels)\n",
    "]\n",
    "with model.invoke(inputs):\n",
    "    for submodule, dictionary in zip(submodules, dictionaries):\n",
    "        x = submodule.output\n",
    "        is_resid = type(x.shape) == tuple\n",
    "        if is_resid:\n",
    "            x = x[0]\n",
    "        x_hat = dictionary(x)\n",
    "        residual = x - x_hat\n",
    "        \n",
    "        f = dictionary.encode(x)\n",
    "        ablation_idxs = to_ablate[submodule]\n",
    "        f[:, -1, t.Tensor(ablation_idxs).long()] = ablation_values[submodule]\n",
    "        x_hat = dictionary.decode(f)\n",
    "        if is_resid:\n",
    "            submodule.output[0][:] = x_hat + residual\n",
    "        else:\n",
    "            submodule.output = x_hat + residual\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "preds = probe(acts).round().long()\n",
    "acc = (preds == labels).float().mean().item()\n",
    "print(f'acc on ambiguous: {acc}')\n",
    "\n",
    "t.manual_seed(42)\n",
    "# get accuracy on disambiguating test set\n",
    "test_data = pd.read_csv('data/test_data.csv')\n",
    "feat1_labels = t.randint(0, 2, (len(test_data),)).to(device)\n",
    "feat2_labels = t.randint(0, 2, (len(test_data),)).to(device)\n",
    "inputs = []\n",
    "for (_, row), label1, label2 in zip(test_data.iterrows(), feat1_labels, feat2_labels):\n",
    "    if label1 == 0 and label2 == 0:\n",
    "        inputs.append(row['singular'])\n",
    "    elif label1 == 0 and label2 == 1:\n",
    "        inputs.append(row['singular'].upper())\n",
    "    elif label1 == 1 and label2 == 0:\n",
    "        inputs.append(row['plural'])\n",
    "    elif label1 == 1 and label2 == 1:\n",
    "        inputs.append(row['plural'].upper())\n",
    "\n",
    "with model.invoke(inputs):\n",
    "    for submodule, dictionary in zip(submodules, dictionaries):\n",
    "        x = submodule.output\n",
    "        is_resid = type(x.shape) == tuple\n",
    "        if is_resid:\n",
    "            x = x[0]\n",
    "        x_hat = dictionary(x)\n",
    "        residual = x - x_hat\n",
    "        \n",
    "        f = dictionary.encode(x)\n",
    "        ablation_idxs = to_ablate[submodule]\n",
    "        f[:, :, t.Tensor(ablation_idxs).long()] = 0.\n",
    "        x_hat = dictionary.decode(f)\n",
    "        if is_resid:\n",
    "            submodule.output[0][:] = x_hat + residual\n",
    "        else:\n",
    "            submodule.output = x_hat + residual\n",
    "    acts = model.gpt_neox.layers[layer].output[0][:,-1,:].save()\n",
    "acts = acts.value.clone()\n",
    "\n",
    "preds = probe(acts).round().long()\n",
    "feat1_acc = (preds == feat1_labels).float().mean().item()\n",
    "feat2_acc = (preds == feat2_labels).float().mean().item()\n",
    "print(f'feat1_acc: {feat1_acc}, feat2_acc: {feat2_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ling acc: 0.9539930555555556\n",
      "surface acc: 0.6663995726495726\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json('/share/data/datasets/msgs/syntactic_category_lexical_content_the/test.jsonl', lines=True)\n",
    "\n",
    "ling_accs, surface_accs = [], []\n",
    "# get accuracy on test data\n",
    "for batch_idx in range(len(test_data) // batch_size):\n",
    "    inputs = test_data['sentence'][batch_idx * batch_size:(batch_idx + 1) * batch_size].tolist()\n",
    "    ling_labels = test_data['linguistic_feature_label'][batch_idx * batch_size:(batch_idx + 1) * batch_size].tolist()\n",
    "    surface_labels = test_data['surface_feature_label'][batch_idx * batch_size:(batch_idx + 1) * batch_size].tolist()\n",
    "\n",
    "    with model.invoke(inputs) as invoker:\n",
    "        hidden_states = model.gpt_neox.layers[-3].output[0].save()\n",
    "    \n",
    "    with t.no_grad():\n",
    "        preds = probe(hidden_states.value)\n",
    "        ling_acc = (preds.round() == t.Tensor(ling_labels).to('cuda:0')).float().mean()\n",
    "        surface_acc = (preds.round() == t.Tensor(surface_labels).to('cuda:0')).float().mean()\n",
    "        ling_accs.append(ling_acc.item())\n",
    "        surface_accs.append(surface_acc.item())\n",
    "\n",
    "print('ling acc:', sum(ling_accs) / len(ling_accs))\n",
    "print('surface acc:', sum(surface_accs) / len(surface_accs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attribution import patching_effect\n",
    "from dictionary_learning.dictionary import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4021, 0.0954], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = \"All grandsons do resemble the print and Debra is an organized child.\"\n",
    "patch = \"All grandsons do resemble a print and Debra is an banana child.\"\n",
    "\n",
    "with model.invoke([clean, patch]) as invoker:\n",
    "    hidden_states = model.gpt_neox.layers[-3].output[0].save()\n",
    "\n",
    "with t.no_grad():\n",
    "    preds = probe(hidden_states.value)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn(model):\n",
    "    return probe(model.gpt_neox.layers[-3].output[0])\n",
    "\n",
    "submodules = [\n",
    "    model.gpt_neox.layers[i] for i in range(4)\n",
    "] + [\n",
    "    model.gpt_neox.layers[i].mlp for i in range(4)\n",
    "]\n",
    "dictionaries = []\n",
    "for i in range(4):\n",
    "    dictionary = AutoEncoder(512, 64 * 512).to(device)\n",
    "    dictionary.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/resid_out_layer{i}/0_32768/ae.pt'))\n",
    "    dictionaries.append(dictionary)\n",
    "for i in range(4):\n",
    "    dictionary = AutoEncoder(512, 64 * 512).to(device)\n",
    "    dictionary.load_state_dict(t.load(f'/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/mlp_out_layer{i}/1_32768/ae.pt'))\n",
    "    dictionaries.append(dictionary)\n",
    "\n",
    "out = patching_effect(\n",
    "    clean,\n",
    "    patch,\n",
    "    model,\n",
    "    submodules,\n",
    "    dictionaries,\n",
    "    metric_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total effect: tensor([-0.7627], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Layer 0:\n",
      "    Multindex: (0, 6, 23084), Value: -0.31019383668899536\n",
      "    Multindex: (0, 6, 29115), Value: -0.2026602178812027\n",
      "    Multindex: (0, 12, 9247), Value: 0.23665377497673035\n",
      "    Multindex: (0, 12, 19133), Value: -0.13597454130649567\n",
      "    Multindex: (0, 13, 1147), Value: 0.10391081869602203\n",
      "    Multindex: (0, 13, 1256), Value: -0.12887312471866608\n",
      "    Multindex: (0, 13, 3385), Value: -0.34761813282966614\n",
      "    Multindex: (0, 13, 3613), Value: -0.11544839292764664\n",
      "    Multindex: (0, 13, 5702), Value: -11.003226280212402\n",
      "    Multindex: (0, 13, 5962), Value: -0.18838448822498322\n",
      "    Multindex: (0, 13, 6959), Value: -0.9820340871810913\n",
      "    Multindex: (0, 13, 15146), Value: -0.12887312471866608\n",
      "    Multindex: (0, 13, 25951), Value: -0.24457168579101562\n",
      "    Multindex: (0, 13, 26640), Value: -0.25634047389030457\n",
      "    Multindex: (0, 13, 27692), Value: -0.12028089165687561\n",
      "    Multindex: (0, 13, 31525), Value: -0.12461315840482712\n",
      "    Multindex: (0, 13, 32650), Value: -0.16245757043361664\n",
      "Layer 1:\n",
      "    Multindex: (0, 6, 588), Value: -0.16466379165649414\n",
      "    Multindex: (0, 13, 245), Value: -0.1918429285287857\n",
      "    Multindex: (0, 13, 303), Value: -0.9617262482643127\n",
      "    Multindex: (0, 13, 614), Value: -0.4203931391239166\n",
      "    Multindex: (0, 13, 639), Value: -0.1067311018705368\n",
      "    Multindex: (0, 13, 1322), Value: -0.11249381303787231\n",
      "    Multindex: (0, 13, 2223), Value: -0.1590975821018219\n",
      "    Multindex: (0, 13, 4875), Value: -0.22198885679244995\n",
      "    Multindex: (0, 13, 7079), Value: -0.1313270777463913\n",
      "    Multindex: (0, 13, 7541), Value: 0.21306736767292023\n",
      "    Multindex: (0, 13, 8150), Value: -0.1918429285287857\n",
      "    Multindex: (0, 13, 9908), Value: -0.13814546167850494\n",
      "    Multindex: (0, 13, 16024), Value: -0.17133969068527222\n",
      "    Multindex: (0, 13, 20331), Value: -1.2441682815551758\n",
      "    Multindex: (0, 13, 23013), Value: -0.18849270045757294\n",
      "    Multindex: (0, 13, 23657), Value: -0.12274052947759628\n",
      "    Multindex: (0, 13, 25848), Value: -0.3059385120868683\n",
      "    Multindex: (0, 13, 29820), Value: -0.1918429285287857\n",
      "    Multindex: (0, 13, 30623), Value: 0.18556568026542664\n",
      "    Multindex: (0, 13, 31453), Value: -0.3648081123828888\n",
      "Layer 2:\n",
      "    Multindex: (0, 13, 5121), Value: -0.16367250680923462\n",
      "    Multindex: (0, 13, 7140), Value: -0.178150936961174\n",
      "    Multindex: (0, 13, 8271), Value: -0.16367250680923462\n",
      "    Multindex: (0, 13, 17322), Value: -0.6946452260017395\n",
      "    Multindex: (0, 13, 19819), Value: -0.10428597778081894\n",
      "    Multindex: (0, 13, 20536), Value: -0.16367250680923462\n",
      "    Multindex: (0, 13, 23880), Value: 0.10106822103261948\n",
      "    Multindex: (0, 13, 24445), Value: -0.15478013455867767\n",
      "    Multindex: (0, 13, 25117), Value: -0.3223865330219269\n",
      "    Multindex: (0, 13, 26060), Value: 0.19325946271419525\n",
      "    Multindex: (0, 13, 28532), Value: -0.5902589559555054\n",
      "Layer 3:\n",
      "    Multindex: (0, 13, 1196), Value: -0.14947494864463806\n",
      "    Multindex: (0, 13, 6716), Value: 0.15161971747875214\n",
      "    Multindex: (0, 13, 11808), Value: -0.11084704846143723\n",
      "    Multindex: (0, 13, 18212), Value: -0.1517772376537323\n",
      "    Multindex: (0, 13, 27249), Value: -0.10479556024074554\n",
      "    Multindex: (0, 13, 27731), Value: 0.16034795343875885\n",
      "    Multindex: (0, 13, 28315), Value: -0.24731893837451935\n",
      "    Multindex: (0, 13, 28765), Value: -0.15697763860225677\n",
      "    Multindex: (0, 13, 31665), Value: -0.19916509091854095\n",
      "Layer 4:\n",
      "    Multindex: (0, 6, 11587), Value: -0.5147899985313416\n",
      "    Multindex: (0, 6, 25244), Value: -2.2249109745025635\n",
      "    Multindex: (0, 13, 11113), Value: -0.12203294783830643\n",
      "    Multindex: (0, 13, 22504), Value: -0.1502879410982132\n",
      "    Multindex: (0, 13, 23022), Value: -0.873496949672699\n",
      "    Multindex: (0, 13, 28362), Value: -0.30438944697380066\n",
      "    Multindex: (0, 13, 29638), Value: -0.2694805860519409\n",
      "    Multindex: (0, 13, 30628), Value: -13.042832374572754\n",
      "    Multindex: (0, 13, 32682), Value: -0.17399896681308746\n",
      "Layer 5:\n",
      "    Multindex: (0, 13, 10300), Value: -0.1266690045595169\n",
      "    Multindex: (0, 13, 17180), Value: -0.29111361503601074\n",
      "    Multindex: (0, 13, 19002), Value: -0.29111361503601074\n",
      "    Multindex: (0, 13, 20568), Value: -0.4593691825866699\n",
      "    Multindex: (0, 13, 29711), Value: -0.10204741358757019\n",
      "    Multindex: (0, 13, 32550), Value: -0.10581643134355545\n",
      "Layer 6:\n",
      "    Multindex: (0, 13, 11804), Value: 0.2141132354736328\n",
      "Layer 7:\n"
     ]
    }
   ],
   "source": [
    "effects, total_effect = out\n",
    "print(f\"Total effect: {total_effect}\")\n",
    "for layer, submodule in enumerate(submodules):\n",
    "    print(f\"Layer {layer}:\")\n",
    "    effect = effects[submodule]\n",
    "    for feature_idx in t.nonzero(effect):\n",
    "        value = effect[tuple(feature_idx)]\n",
    "        if value.abs() > 0.1:\n",
    "            print(f\"    Multindex: {tuple(feature_idx.tolist())}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: All\n",
      "1:  gr\n",
      "2: ands\n",
      "3: ons\n",
      "4:  do\n",
      "5:  resemble\n",
      "6:  the\n",
      "7:  print\n",
      "8:  and\n",
      "9:  De\n",
      "10: bra\n",
      "11:  is\n",
      "12:  an\n",
      "13:  organized\n",
      "14:  child\n",
      "15: .\n"
     ]
    }
   ],
   "source": [
    "for i, tok in enumerate(invoker.input.input_ids[0]):\n",
    "    print(f\"{i}: {model.tokenizer.decode([tok])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
